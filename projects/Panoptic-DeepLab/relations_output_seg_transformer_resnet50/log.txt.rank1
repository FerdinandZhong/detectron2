[10/09 17:21:09] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:21:10] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:21:10] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:21:10] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:21:10] detectron2.utils.env INFO: Using a generated random seed 10324614
[10/09 17:21:13] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res2): Linear(in_features=256, out_features=32, bias=True)
      (res3): Linear(in_features=512, out_features=32, bias=True)
      (res5): Linear(in_features=2048, out_features=32, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=32, out_features=96, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=32, out_features=32, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=32, out_features=96, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=96, out_features=32, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=32, out_features=96, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=32, out_features=32, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=32, out_features=96, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=96, out_features=32, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.0, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=32, out_features=64, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj_cls): Linear(in_features=32, out_features=32, bias=True)
      (proj_rel): Linear(in_features=32, out_features=32, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (cls_fc): Linear(in_features=32, out_features=1, bias=True)
    (rel_fc): Linear(in_features=32, out_features=1, bias=True)
  )
)
[10/09 17:21:13] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/09 17:21:13] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/09 17:21:14] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/09 17:21:14] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/09 17:21:14] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/09 17:21:14] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/09 17:21:14] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/09 17:21:14] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/09 17:21:14] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/09 17:21:15] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res2.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/09 17:21:15] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/09 17:21:15] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/09 17:21:31] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/root/Projects/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 274, in run_step
    loss_dict = self.model(data)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1008, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 969, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 130, in forward
    sem_seg_results, sem_seg_losses = self.sem_seg_head(features, targets, weights)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 371, in forward
    y = self.layers(features)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 382, in layers
    y = super().layers(features)
  File "/root/Projects/detectron2/projects/DeepLab/deeplab/semantic_seg.py", line 241, in layers
    proj_x = self.decoder[f]["project_conv"](x)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/detectron2/layers/aspp.py", line 139, in forward
    res.append(conv(x))
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/detectron2/layers/blocks.py", line 111, in forward
    return self.pointwise(self.depthwise(x))
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/detectron2/layers/wrappers.py", line 113, in forward
    x = F.conv2d(
RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 1; 31.75 GiB total capacity; 2.31 GiB already allocated; 4.50 MiB free; 2.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/09 17:21:31] detectron2.engine.hooks INFO: Total training time: 0:00:16 (0:00:00 on hooks)
[10/09 17:25:47] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:25:48] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:25:48] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:25:48] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:25:48] detectron2.utils.env INFO: Using a generated random seed 48501239
[10/09 17:26:02] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res2): Linear(in_features=256, out_features=256, bias=True)
      (res3): Linear(in_features=512, out_features=256, bias=True)
      (res5): Linear(in_features=2048, out_features=256, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.0, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=256, out_features=512, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj_cls): Linear(in_features=256, out_features=256, bias=True)
      (proj_rel): Linear(in_features=256, out_features=256, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (cls_fc): Linear(in_features=256, out_features=1, bias=True)
    (rel_fc): Linear(in_features=256, out_features=1, bias=True)
  )
)
[10/09 17:26:02] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/09 17:26:03] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/09 17:26:03] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/09 17:26:03] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/09 17:26:03] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/09 17:26:03] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/09 17:26:03] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/09 17:26:03] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/09 17:26:03] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/09 17:26:04] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res2.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/09 17:26:04] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/09 17:26:04] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/09 17:26:19] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/root/Projects/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 274, in run_step
    loss_dict = self.model(data)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1008, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 969, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 156, in forward
    panoptic_relations_results, panoptic_relations_losses = self.psg_relation_net(
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/psg_relations.py", line 120, in forward
    out_rel, out_cls = self.layers(features)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/psg_relations.py", line 137, in layers
    out = self.tf_encoder(out)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/transformer.py", line 125, in forward
    x = block(x)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/transformer.py", line 84, in forward
    x = x + self.drop_path(self.attn(self.norm1(x)))
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/transformer.py", line 47, in forward
    attn = (q @ k.transpose(-2, -1)) * self.scale
RuntimeError: CUDA out of memory. Tried to allocate 8.41 GiB (GPU 1; 31.75 GiB total capacity; 20.54 GiB already allocated; 2.39 GiB free; 28.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/09 17:26:19] detectron2.engine.hooks INFO: Total training time: 0:00:15 (0:00:00 on hooks)
[10/09 17:27:06] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:27:07] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:27:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:27:07] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:27:07] detectron2.utils.env INFO: Using a generated random seed 7526346
[10/09 17:27:11] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res2): Linear(in_features=256, out_features=64, bias=True)
      (res3): Linear(in_features=512, out_features=64, bias=True)
      (res5): Linear(in_features=2048, out_features=64, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=64, out_features=192, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=192, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=192, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=64, out_features=192, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=192, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=192, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.0, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=64, out_features=128, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj_cls): Linear(in_features=64, out_features=64, bias=True)
      (proj_rel): Linear(in_features=64, out_features=64, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (cls_fc): Linear(in_features=64, out_features=1, bias=True)
    (rel_fc): Linear(in_features=64, out_features=1, bias=True)
  )
)
[10/09 17:27:11] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/09 17:27:11] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/09 17:27:12] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/09 17:27:12] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/09 17:27:12] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/09 17:27:12] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/09 17:27:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/09 17:27:12] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/09 17:27:12] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/09 17:27:12] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res2.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/09 17:27:12] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/09 17:27:12] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/09 17:27:27] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/root/Projects/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 286, in run_step
    losses.backward()
  File "/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 8.41 GiB (GPU 1; 31.75 GiB total capacity; 19.59 GiB already allocated; 2.43 GiB free; 28.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/09 17:27:27] detectron2.engine.hooks INFO: Total training time: 0:00:15 (0:00:00 on hooks)
[10/09 17:29:16] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:29:17] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:29:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:29:17] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:29:17] detectron2.utils.env INFO: Using a generated random seed 17651109
[10/09 17:29:21] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res2): Linear(in_features=256, out_features=64, bias=True)
      (res3): Linear(in_features=512, out_features=64, bias=True)
      (res5): Linear(in_features=2048, out_features=64, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=64, out_features=192, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=192, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=192, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=64, out_features=192, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=192, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=192, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.0, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=64, out_features=128, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj_cls): Linear(in_features=64, out_features=64, bias=True)
      (proj_rel): Linear(in_features=64, out_features=64, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (cls_fc): Linear(in_features=64, out_features=1, bias=True)
    (rel_fc): Linear(in_features=64, out_features=1, bias=True)
  )
)
[10/09 17:29:21] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/09 17:29:21] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/09 17:29:22] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/09 17:29:22] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/09 17:29:22] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/09 17:29:22] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/09 17:29:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/09 17:29:22] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/09 17:29:22] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/09 17:29:22] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res2.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/09 17:29:22] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/09 17:29:22] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/09 17:29:38] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/root/Projects/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 286, in run_step
    losses.backward()
  File "/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 8.41 GiB (GPU 1; 31.75 GiB total capacity; 19.59 GiB already allocated; 2.43 GiB free; 28.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/09 17:29:38] detectron2.engine.hooks INFO: Total training time: 0:00:15 (0:00:00 on hooks)
[10/09 17:31:44] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:31:45] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:31:45] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:31:45] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:31:45] detectron2.utils.env INFO: Using a generated random seed 45727036
[10/09 17:31:49] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res2): Linear(in_features=256, out_features=64, bias=True)
      (res3): Linear(in_features=512, out_features=64, bias=True)
      (res5): Linear(in_features=2048, out_features=64, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=64, out_features=192, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=192, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=192, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.0, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=64, out_features=128, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj_cls): Linear(in_features=64, out_features=64, bias=True)
      (proj_rel): Linear(in_features=64, out_features=64, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (cls_fc): Linear(in_features=64, out_features=1, bias=True)
    (rel_fc): Linear(in_features=64, out_features=1, bias=True)
  )
)
[10/09 17:31:49] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/09 17:31:49] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/09 17:31:50] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/09 17:31:50] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/09 17:31:51] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/09 17:31:51] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/09 17:31:51] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/09 17:31:51] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/09 17:31:51] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/09 17:31:51] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res2.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/09 17:31:51] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/09 17:31:51] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/09 17:32:07] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/root/Projects/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 286, in run_step
    losses.backward()
  File "/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 8.41 GiB (GPU 1; 31.75 GiB total capacity; 19.35 GiB already allocated; 2.43 GiB free; 28.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/09 17:32:07] detectron2.engine.hooks INFO: Total training time: 0:00:15 (0:00:00 on hooks)
[10/09 17:32:40] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:32:41] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:32:41] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:32:41] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:32:41] detectron2.utils.env INFO: Using a generated random seed 41556850
[10/09 17:32:45] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res2): Linear(in_features=256, out_features=64, bias=True)
      (res3): Linear(in_features=512, out_features=64, bias=True)
      (res5): Linear(in_features=2048, out_features=64, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=64, out_features=192, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=192, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=192, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=64, out_features=192, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=192, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=192, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.0, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=64, out_features=128, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj_cls): Linear(in_features=64, out_features=64, bias=True)
      (proj_rel): Linear(in_features=64, out_features=64, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (cls_fc): Linear(in_features=64, out_features=1, bias=True)
    (rel_fc): Linear(in_features=64, out_features=1, bias=True)
  )
)
[10/09 17:32:45] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/09 17:32:45] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/09 17:32:46] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/09 17:32:46] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/09 17:32:46] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/09 17:32:46] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/09 17:32:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/09 17:32:46] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/09 17:32:46] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/09 17:32:46] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res2.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/09 17:32:46] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/09 17:32:46] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/09 17:33:56] detectron2.engine.hooks INFO: Overall training speed: 119 iterations in 0:00:54 (0.4558 s / it)
[10/09 17:33:56] detectron2.engine.hooks INFO: Total training time: 0:00:54 (0:00:00 on hooks)
[10/09 17:47:31] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:47:32] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:47:32] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:47:32] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m5.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mrelative_range[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(0.8, 0.8)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:47:32] detectron2.utils.env INFO: Using a generated random seed 32925797
[10/09 17:50:24] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:50:25] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:50:25] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:50:25] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m5.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(512, 512)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:50:25] detectron2.utils.env INFO: Using a generated random seed 25443396
[10/09 17:51:09] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:51:10] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:51:10] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:51:10] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m5.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(512, 512)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:51:10] detectron2.utils.env INFO: Using a generated random seed 10733256
[10/09 17:51:17] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(32, 32), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(32, 32), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res2): Linear(in_features=256, out_features=128, bias=True)
      (res3): Linear(in_features=512, out_features=128, bias=True)
      (res5): Linear(in_features=2048, out_features=128, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=128, out_features=384, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=384, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=384, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=128, out_features=384, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=384, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=384, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.0, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=128, out_features=256, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj_cls): Linear(in_features=128, out_features=128, bias=True)
      (proj_rel): Linear(in_features=128, out_features=128, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (cls_fc): Linear(in_features=128, out_features=1, bias=True)
    (rel_fc): Linear(in_features=128, out_features=1, bias=True)
  )
)
[10/09 17:51:17] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[512, 512]), RandomFlip()]
[10/09 17:51:18] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/09 17:51:18] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/09 17:51:18] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/09 17:51:18] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/09 17:51:18] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/09 17:51:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/09 17:51:19] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/09 17:51:19] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/09 17:51:19] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res2.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/09 17:51:19] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/09 17:51:19] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/09 17:51:34] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/root/Projects/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 274, in run_step
    loss_dict = self.model(data)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1008, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 969, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 146, in forward
    sem_seg_results, sem_seg_losses = self.sem_seg_head(features, targets, weights)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 422, in forward
    y = self.layers(features)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 433, in layers
    y = super().layers(features)
  File "/root/Projects/detectron2/projects/DeepLab/deeplab/semantic_seg.py", line 241, in layers
    proj_x = self.decoder[f]["project_conv"](x)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/detectron2/layers/aspp.py", line 133, in forward
    raise ValueError(
ValueError: `pool_kernel_size` must be divisible by the shape of inputs. Input size: torch.Size([40, 40]) `pool_kernel_size`: (32, 32)
[10/09 17:51:34] detectron2.engine.hooks INFO: Total training time: 0:00:15 (0:00:00 on hooks)
[10/09 17:52:28] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:52:29] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:52:29] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:52:29] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m5.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:52:29] detectron2.utils.env INFO: Using a generated random seed 29572886
[10/09 17:52:36] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res2): Linear(in_features=256, out_features=128, bias=True)
      (res3): Linear(in_features=512, out_features=128, bias=True)
      (res5): Linear(in_features=2048, out_features=128, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=128, out_features=384, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=384, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=384, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=128, out_features=384, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=384, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=384, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.0, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=128, out_features=256, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj_cls): Linear(in_features=128, out_features=128, bias=True)
      (proj_rel): Linear(in_features=128, out_features=128, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (cls_fc): Linear(in_features=128, out_features=1, bias=True)
    (rel_fc): Linear(in_features=128, out_features=1, bias=True)
  )
)
[10/09 17:52:36] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/09 17:52:37] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/09 17:52:37] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/09 17:52:37] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/09 17:52:37] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/09 17:52:37] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/09 17:52:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/09 17:52:37] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/09 17:52:37] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/09 17:52:38] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res2.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/09 17:52:38] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/09 17:52:38] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/09 17:52:53] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/root/Projects/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/root/Projects/detectron2/detectron2/engine/train_loop.py", line 274, in run_step
    loss_dict = self.model(data)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1008, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 969, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 175, in forward
    panoptic_relations_results, panoptic_relations_losses = self.psg_relation_net(
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/psg_relations.py", line 165, in forward
    out_rel, out_cls = self.layers(features)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/psg_relations.py", line 182, in layers
    out = self.tf_encoder(out)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/transformer.py", line 184, in forward
    x = block(x)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/transformer.py", line 117, in forward
    x = x + self.drop_path(self.attn(self.norm1(x)))
  File "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/root/Projects/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/transformer.py", line 59, in forward
    attn = (q @ k.transpose(-2, -1)) * self.scale
RuntimeError: CUDA out of memory. Tried to allocate 8.41 GiB (GPU 1; 31.75 GiB total capacity; 19.83 GiB already allocated; 2.44 GiB free; 28.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/09 17:52:53] detectron2.engine.hooks INFO: Total training time: 0:00:15 (0:00:00 on hooks)
[10/09 17:53:16] detectron2 INFO: Rank of current process: 1. World size: 2
[10/09 17:53:17] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/Projects/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/09 17:53:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/09 17:53:17] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m5.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet50[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000

[10/09 17:53:17] detectron2.utils.env INFO: Using a generated random seed 17786367
[10/09 17:53:24] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res2): Linear(in_features=256, out_features=128, bias=True)
      (res3): Linear(in_features=512, out_features=128, bias=True)
      (res5): Linear(in_features=2048, out_features=128, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=128, out_features=384, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=384, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=384, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=128, out_features=384, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=384, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=384, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.0, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=128, out_features=256, bias=True)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj_cls): Linear(in_features=128, out_features=128, bias=True)
      (proj_rel): Linear(in_features=128, out_features=128, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (cls_fc): Linear(in_features=128, out_features=1, bias=True)
    (rel_fc): Linear(in_features=128, out_features=1, bias=True)
  )
)
[10/09 17:53:24] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/09 17:53:24] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/09 17:53:25] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/09 17:53:25] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/09 17:53:26] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/09 17:53:26] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/09 17:53:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/09 17:53:26] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/09 17:53:26] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/09 17:53:26] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res2.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/09 17:53:26] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/09 17:53:26] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/09 18:03:42] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 1980         |    bicycle    | 80           |      car      | 332          |
|  motorcycle   | 51           |   airplane    | 15           |      bus      | 38           |
|     train     | 21           |     truck     | 70           |     boat      | 53           |
| traffic light | 93           | fire hydrant  | 9            |   stop sign   | 8            |
| parking meter | 1            |     bench     | 56           |     bird      | 86           |
|      cat      | 8            |      dog      | 18           |     horse     | 42           |
|     sheep     | 47           |      cow      | 30           |   elephant    | 29           |
|     bear      | 10           |     zebra     | 47           |    giraffe    | 33           |
|   backpack    | 55           |   umbrella    | 44           |    handbag    | 130          |
|      tie      | 33           |   suitcase    | 18           |    frisbee    | 7            |
|     skis      | 44           |   snowboard   | 11           |  sports ball  | 46           |
|     kite      | 94           | baseball bat  | 24           | baseball gl.. | 32           |
|  skateboard   | 37           |   surfboard   | 55           | tennis racket | 30           |
|    bottle     | 77           |  wine glass   | 41           |      cup      | 104          |
|     fork      | 23           |     knife     | 30           |     spoon     | 23           |
|     bowl      | 51           |    banana     | 52           |     apple     | 14           |
|   sandwich    | 5            |    orange     | 13           |   broccoli    | 3            |
|    carrot     | 16           |    hot dog    | 8            |     pizza     | 14           |
|     donut     | 9            |     cake      | 15           |     chair     | 197          |
|     couch     | 17           | potted plant  | 10           |      bed      | 10           |
| dining table  | 45           |    toilet     | 6            |      tv       | 12           |
|    laptop     | 16           |     mouse     | 2            |    remote     | 23           |
|   keyboard    | 2            |  cell phone   | 25           |   microwave   | 0            |
|     oven      | 3            |    toaster    | 0            |     sink      | 7            |
| refrigerator  | 2            |     book      | 74           |     clock     | 11           |
|     vase      | 1            |   scissors    | 0            |  teddy bear   | 33           |
|  hair drier   | 0            |  toothbrush   | 8            |    banner     | 29           |
|    blanket    | 13           |    bridge     | 9            |   cardboard   | 14           |
|    counter    | 7            |    curtain    | 12           |  door-stuff   | 30           |
|  floor-wood   | 16           |    flower     | 9            |     fruit     | 6            |
|    gravel     | 10           |     house     | 33           |     light     | 41           |
| mirror-stuff  | 7            |      net      | 7            |    pillow     | 7            |
|   platform    | 16           | playingfield  | 39           |   railroad    | 17           |
|     river     | 10           |     road      | 101          |     roof      | 20           |
|     sand      | 28           |      sea      | 53           |     shelf     | 19           |
|     snow      | 27           |    stairs     | 16           |     tent      | 11           |
|     towel     | 12           |  wall-brick   | 24           |  wall-stone   | 15           |
|   wall-tile   | 12           |   wall-wood   | 34           |  water-other  | 10           |
| window-blind  | 8            | window-other  | 40           |  tree-merged  | 224          |
| fence-merged  | 91           | ceiling-mer.. | 32           | sky-other-m.. | 233          |
| cabinet-mer.. | 16           | table-merged  | 46           | floor-other.. | 42           |
| pavement-me.. | 134          | mountain-me.. | 31           | grass-merged  | 128          |
|  dirt-merged  | 57           | paper-merged  | 29           | food-other-.. | 24           |
| building-ot.. | 152          |  rock-merged  | 22           | wall-other-.. | 145          |
|  rug-merged   | 14           |               |              |               |              |
|     total     | 7001         |               |              |               |              |[0m
[10/09 18:03:42] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/09 18:03:42] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/09 18:03:42] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/09 18:03:42] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/09 18:03:59] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0019 s/iter. Inference: 0.2686 s/iter. Eval: 0.0278 s/iter. Total: 0.2984 s/iter. ETA=0:01:11
[10/09 18:04:04] detectron2.evaluation.evaluator INFO: Inference done 28/250. Dataloading: 0.0011 s/iter. Inference: 0.2653 s/iter. Eval: 0.0289 s/iter. Total: 0.2954 s/iter. ETA=0:01:05
[10/09 18:04:09] detectron2.evaluation.evaluator INFO: Inference done 46/250. Dataloading: 0.0012 s/iter. Inference: 0.2612 s/iter. Eval: 0.0288 s/iter. Total: 0.2913 s/iter. ETA=0:00:59
[10/09 18:04:14] detectron2.evaluation.evaluator INFO: Inference done 63/250. Dataloading: 0.0014 s/iter. Inference: 0.2625 s/iter. Eval: 0.0296 s/iter. Total: 0.2935 s/iter. ETA=0:00:54
[10/09 18:04:19] detectron2.evaluation.evaluator INFO: Inference done 80/250. Dataloading: 0.0014 s/iter. Inference: 0.2637 s/iter. Eval: 0.0300 s/iter. Total: 0.2952 s/iter. ETA=0:00:50
[10/09 18:04:24] detectron2.evaluation.evaluator INFO: Inference done 98/250. Dataloading: 0.0014 s/iter. Inference: 0.2631 s/iter. Eval: 0.0297 s/iter. Total: 0.2944 s/iter. ETA=0:00:44
[10/09 18:04:29] detectron2.evaluation.evaluator INFO: Inference done 115/250. Dataloading: 0.0014 s/iter. Inference: 0.2633 s/iter. Eval: 0.0299 s/iter. Total: 0.2946 s/iter. ETA=0:00:39
[10/09 18:04:34] detectron2.evaluation.evaluator INFO: Inference done 133/250. Dataloading: 0.0014 s/iter. Inference: 0.2617 s/iter. Eval: 0.0294 s/iter. Total: 0.2925 s/iter. ETA=0:00:34
[10/09 18:04:40] detectron2.evaluation.evaluator INFO: Inference done 151/250. Dataloading: 0.0015 s/iter. Inference: 0.2616 s/iter. Eval: 0.0293 s/iter. Total: 0.2924 s/iter. ETA=0:00:28
[10/09 18:04:45] detectron2.evaluation.evaluator INFO: Inference done 169/250. Dataloading: 0.0015 s/iter. Inference: 0.2615 s/iter. Eval: 0.0295 s/iter. Total: 0.2925 s/iter. ETA=0:00:23
[10/09 18:04:50] detectron2.evaluation.evaluator INFO: Inference done 187/250. Dataloading: 0.0015 s/iter. Inference: 0.2607 s/iter. Eval: 0.0293 s/iter. Total: 0.2915 s/iter. ETA=0:00:18
[10/09 18:04:55] detectron2.evaluation.evaluator INFO: Inference done 204/250. Dataloading: 0.0015 s/iter. Inference: 0.2612 s/iter. Eval: 0.0294 s/iter. Total: 0.2922 s/iter. ETA=0:00:13
[10/09 18:05:00] detectron2.evaluation.evaluator INFO: Inference done 222/250. Dataloading: 0.0015 s/iter. Inference: 0.2611 s/iter. Eval: 0.0293 s/iter. Total: 0.2919 s/iter. ETA=0:00:08
[10/09 18:05:05] detectron2.evaluation.evaluator INFO: Inference done 240/250. Dataloading: 0.0015 s/iter. Inference: 0.2606 s/iter. Eval: 0.0292 s/iter. Total: 0.2913 s/iter. ETA=0:00:02
[10/09 18:05:09] detectron2.evaluation.evaluator INFO: Total inference time: 0:01:11.645118 (0.292429 s / iter per device, on 2 devices)
[10/09 18:05:09] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:03 (0.260323 s / iter per device, on 2 devices)
[10/09 18:05:15] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/09 18:15:10] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/09 18:15:10] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/09 18:15:10] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/09 18:15:10] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/09 18:15:25] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0023 s/iter. Inference: 0.1905 s/iter. Eval: 0.0224 s/iter. Total: 0.2153 s/iter. ETA=0:00:51
[10/09 18:15:30] detectron2.evaluation.evaluator INFO: Inference done 34/250. Dataloading: 0.0014 s/iter. Inference: 0.1915 s/iter. Eval: 0.0248 s/iter. Total: 0.2177 s/iter. ETA=0:00:47
[10/09 18:15:36] detectron2.evaluation.evaluator INFO: Inference done 57/250. Dataloading: 0.0014 s/iter. Inference: 0.1934 s/iter. Eval: 0.0254 s/iter. Total: 0.2202 s/iter. ETA=0:00:42
[10/09 18:15:41] detectron2.evaluation.evaluator INFO: Inference done 80/250. Dataloading: 0.0014 s/iter. Inference: 0.1934 s/iter. Eval: 0.0259 s/iter. Total: 0.2208 s/iter. ETA=0:00:37
[10/09 18:15:46] detectron2.evaluation.evaluator INFO: Inference done 103/250. Dataloading: 0.0015 s/iter. Inference: 0.1941 s/iter. Eval: 0.0259 s/iter. Total: 0.2216 s/iter. ETA=0:00:32
[10/09 18:15:51] detectron2.evaluation.evaluator INFO: Inference done 126/250. Dataloading: 0.0015 s/iter. Inference: 0.1944 s/iter. Eval: 0.0258 s/iter. Total: 0.2218 s/iter. ETA=0:00:27
[10/09 18:15:56] detectron2.evaluation.evaluator INFO: Inference done 149/250. Dataloading: 0.0015 s/iter. Inference: 0.1946 s/iter. Eval: 0.0256 s/iter. Total: 0.2218 s/iter. ETA=0:00:22
[10/09 18:16:01] detectron2.evaluation.evaluator INFO: Inference done 172/250. Dataloading: 0.0015 s/iter. Inference: 0.1947 s/iter. Eval: 0.0257 s/iter. Total: 0.2219 s/iter. ETA=0:00:17
[10/09 18:16:06] detectron2.evaluation.evaluator INFO: Inference done 195/250. Dataloading: 0.0015 s/iter. Inference: 0.1947 s/iter. Eval: 0.0256 s/iter. Total: 0.2219 s/iter. ETA=0:00:12
[10/09 18:16:11] detectron2.evaluation.evaluator INFO: Inference done 218/250. Dataloading: 0.0015 s/iter. Inference: 0.1947 s/iter. Eval: 0.0256 s/iter. Total: 0.2219 s/iter. ETA=0:00:07
[10/09 18:16:16] detectron2.evaluation.evaluator INFO: Inference done 241/250. Dataloading: 0.0015 s/iter. Inference: 0.1947 s/iter. Eval: 0.0255 s/iter. Total: 0.2218 s/iter. ETA=0:00:01
[10/09 18:16:19] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:54.715174 (0.223327 s / iter per device, on 2 devices)
[10/09 18:16:19] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:47 (0.194664 s / iter per device, on 2 devices)
[10/09 18:16:24] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/09 18:26:18] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/09 18:26:18] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/09 18:26:18] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/09 18:26:18] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/09 18:26:34] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0020 s/iter. Inference: 0.1932 s/iter. Eval: 0.0270 s/iter. Total: 0.2222 s/iter. ETA=0:00:53
[10/09 18:26:39] detectron2.evaluation.evaluator INFO: Inference done 34/250. Dataloading: 0.0012 s/iter. Inference: 0.1970 s/iter. Eval: 0.0276 s/iter. Total: 0.2258 s/iter. ETA=0:00:48
[10/09 18:26:44] detectron2.evaluation.evaluator INFO: Inference done 56/250. Dataloading: 0.0013 s/iter. Inference: 0.1979 s/iter. Eval: 0.0279 s/iter. Total: 0.2272 s/iter. ETA=0:00:44
[10/09 18:26:49] detectron2.evaluation.evaluator INFO: Inference done 78/250. Dataloading: 0.0014 s/iter. Inference: 0.1977 s/iter. Eval: 0.0284 s/iter. Total: 0.2276 s/iter. ETA=0:00:39
[10/09 18:26:54] detectron2.evaluation.evaluator INFO: Inference done 100/250. Dataloading: 0.0014 s/iter. Inference: 0.1979 s/iter. Eval: 0.0282 s/iter. Total: 0.2276 s/iter. ETA=0:00:34
[10/09 18:26:59] detectron2.evaluation.evaluator INFO: Inference done 123/250. Dataloading: 0.0014 s/iter. Inference: 0.1977 s/iter. Eval: 0.0281 s/iter. Total: 0.2272 s/iter. ETA=0:00:28
[10/09 18:27:05] detectron2.evaluation.evaluator INFO: Inference done 146/250. Dataloading: 0.0014 s/iter. Inference: 0.1975 s/iter. Eval: 0.0275 s/iter. Total: 0.2265 s/iter. ETA=0:00:23
[10/09 18:27:10] detectron2.evaluation.evaluator INFO: Inference done 168/250. Dataloading: 0.0014 s/iter. Inference: 0.1974 s/iter. Eval: 0.0277 s/iter. Total: 0.2266 s/iter. ETA=0:00:18
[10/09 18:27:15] detectron2.evaluation.evaluator INFO: Inference done 191/250. Dataloading: 0.0014 s/iter. Inference: 0.1975 s/iter. Eval: 0.0276 s/iter. Total: 0.2266 s/iter. ETA=0:00:13
[10/09 18:27:20] detectron2.evaluation.evaluator INFO: Inference done 214/250. Dataloading: 0.0014 s/iter. Inference: 0.1976 s/iter. Eval: 0.0276 s/iter. Total: 0.2267 s/iter. ETA=0:00:08
[10/09 18:27:25] detectron2.evaluation.evaluator INFO: Inference done 237/250. Dataloading: 0.0014 s/iter. Inference: 0.1973 s/iter. Eval: 0.0274 s/iter. Total: 0.2262 s/iter. ETA=0:00:02
[10/09 18:27:28] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:55.748487 (0.227545 s / iter per device, on 2 devices)
[10/09 18:27:28] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:48 (0.197035 s / iter per device, on 2 devices)
[10/09 18:27:34] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/09 18:37:28] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/09 18:37:28] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/09 18:37:28] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/09 18:37:28] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/09 18:37:44] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0015 s/iter. Inference: 0.1975 s/iter. Eval: 0.0282 s/iter. Total: 0.2272 s/iter. ETA=0:00:54
[10/09 18:37:49] detectron2.evaluation.evaluator INFO: Inference done 33/250. Dataloading: 0.0012 s/iter. Inference: 0.2000 s/iter. Eval: 0.0293 s/iter. Total: 0.2306 s/iter. ETA=0:00:50
[10/09 18:37:54] detectron2.evaluation.evaluator INFO: Inference done 55/250. Dataloading: 0.0014 s/iter. Inference: 0.2004 s/iter. Eval: 0.0292 s/iter. Total: 0.2310 s/iter. ETA=0:00:45
[10/09 18:37:59] detectron2.evaluation.evaluator INFO: Inference done 77/250. Dataloading: 0.0014 s/iter. Inference: 0.2007 s/iter. Eval: 0.0296 s/iter. Total: 0.2318 s/iter. ETA=0:00:40
[10/09 18:38:04] detectron2.evaluation.evaluator INFO: Inference done 99/250. Dataloading: 0.0015 s/iter. Inference: 0.2004 s/iter. Eval: 0.0295 s/iter. Total: 0.2314 s/iter. ETA=0:00:34
[10/09 18:38:09] detectron2.evaluation.evaluator INFO: Inference done 121/250. Dataloading: 0.0015 s/iter. Inference: 0.2000 s/iter. Eval: 0.0295 s/iter. Total: 0.2310 s/iter. ETA=0:00:29
[10/09 18:38:14] detectron2.evaluation.evaluator INFO: Inference done 143/250. Dataloading: 0.0015 s/iter. Inference: 0.2001 s/iter. Eval: 0.0290 s/iter. Total: 0.2306 s/iter. ETA=0:00:24
[10/09 18:38:19] detectron2.evaluation.evaluator INFO: Inference done 165/250. Dataloading: 0.0015 s/iter. Inference: 0.1998 s/iter. Eval: 0.0289 s/iter. Total: 0.2303 s/iter. ETA=0:00:19
[10/09 18:38:25] detectron2.evaluation.evaluator INFO: Inference done 187/250. Dataloading: 0.0015 s/iter. Inference: 0.1998 s/iter. Eval: 0.0288 s/iter. Total: 0.2302 s/iter. ETA=0:00:14
[10/09 18:38:30] detectron2.evaluation.evaluator INFO: Inference done 209/250. Dataloading: 0.0015 s/iter. Inference: 0.1996 s/iter. Eval: 0.0288 s/iter. Total: 0.2300 s/iter. ETA=0:00:09
[10/09 18:38:35] detectron2.evaluation.evaluator INFO: Inference done 231/250. Dataloading: 0.0015 s/iter. Inference: 0.1996 s/iter. Eval: 0.0287 s/iter. Total: 0.2299 s/iter. ETA=0:00:04
[10/09 18:38:39] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:56.573083 (0.230911 s / iter per device, on 2 devices)
[10/09 18:38:39] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:48 (0.199220 s / iter per device, on 2 devices)
[10/09 18:38:44] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/09 18:39:04] detectron2.engine.hooks INFO: Overall training speed: 4030 iterations in 0:39:58 (0.5952 s / it)
[10/09 18:39:04] detectron2.engine.hooks INFO: Total training time: 0:45:20 (0:05:22 on hooks)
