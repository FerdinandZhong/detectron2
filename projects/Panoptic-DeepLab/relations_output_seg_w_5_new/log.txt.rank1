[10/08 14:54:33] detectron2 INFO: Rank of current process: 1. World size: 2
[10/08 14:54:34] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/autodl-tmp/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          515.57
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/08 14:54:34] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/08 14:54:34] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-52.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m5.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0005
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m50000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m16
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_w_5_new[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m2000

[10/08 14:54:34] detectron2.utils.env INFO: Using a generated random seed 34916920
[10/08 14:54:35] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=256, out_features=56, bias=True)
    (relation_loss): BCEWithLogitsLoss()
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[10/08 14:54:35] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/08 14:54:35] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/08 14:54:35] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/08 14:54:35] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/08 14:54:36] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/08 14:54:36] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/08 14:54:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[10/08 14:54:36] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/08 14:54:36] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/08 14:54:36] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.fc.{bias, weight}[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/08 14:54:36] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/08 14:54:36] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/08 15:16:10] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 1980         |    bicycle    | 80           |      car      | 332          |
|  motorcycle   | 51           |   airplane    | 15           |      bus      | 38           |
|     train     | 21           |     truck     | 70           |     boat      | 53           |
| traffic light | 93           | fire hydrant  | 9            |   stop sign   | 8            |
| parking meter | 1            |     bench     | 56           |     bird      | 86           |
|      cat      | 8            |      dog      | 18           |     horse     | 42           |
|     sheep     | 47           |      cow      | 30           |   elephant    | 29           |
|     bear      | 10           |     zebra     | 47           |    giraffe    | 33           |
|   backpack    | 55           |   umbrella    | 44           |    handbag    | 130          |
|      tie      | 33           |   suitcase    | 18           |    frisbee    | 7            |
|     skis      | 44           |   snowboard   | 11           |  sports ball  | 46           |
|     kite      | 94           | baseball bat  | 24           | baseball gl.. | 32           |
|  skateboard   | 37           |   surfboard   | 55           | tennis racket | 30           |
|    bottle     | 77           |  wine glass   | 41           |      cup      | 104          |
|     fork      | 23           |     knife     | 30           |     spoon     | 23           |
|     bowl      | 51           |    banana     | 52           |     apple     | 14           |
|   sandwich    | 5            |    orange     | 13           |   broccoli    | 3            |
|    carrot     | 16           |    hot dog    | 8            |     pizza     | 14           |
|     donut     | 9            |     cake      | 15           |     chair     | 197          |
|     couch     | 17           | potted plant  | 10           |      bed      | 10           |
| dining table  | 45           |    toilet     | 6            |      tv       | 12           |
|    laptop     | 16           |     mouse     | 2            |    remote     | 23           |
|   keyboard    | 2            |  cell phone   | 25           |   microwave   | 0            |
|     oven      | 3            |    toaster    | 0            |     sink      | 7            |
| refrigerator  | 2            |     book      | 74           |     clock     | 11           |
|     vase      | 1            |   scissors    | 0            |  teddy bear   | 33           |
|  hair drier   | 0            |  toothbrush   | 8            |    banner     | 29           |
|    blanket    | 13           |    bridge     | 9            |   cardboard   | 14           |
|    counter    | 7            |    curtain    | 12           |  door-stuff   | 30           |
|  floor-wood   | 16           |    flower     | 9            |     fruit     | 6            |
|    gravel     | 10           |     house     | 33           |     light     | 41           |
| mirror-stuff  | 7            |      net      | 7            |    pillow     | 7            |
|   platform    | 16           | playingfield  | 39           |   railroad    | 17           |
|     river     | 10           |     road      | 101          |     roof      | 20           |
|     sand      | 28           |      sea      | 53           |     shelf     | 19           |
|     snow      | 27           |    stairs     | 16           |     tent      | 11           |
|     towel     | 12           |  wall-brick   | 24           |  wall-stone   | 15           |
|   wall-tile   | 12           |   wall-wood   | 34           |  water-other  | 10           |
| window-blind  | 8            | window-other  | 40           |  tree-merged  | 224          |
| fence-merged  | 91           | ceiling-mer.. | 32           | sky-other-m.. | 233          |
| cabinet-mer.. | 16           | table-merged  | 46           | floor-other.. | 42           |
| pavement-me.. | 134          | mountain-me.. | 31           | grass-merged  | 128          |
|  dirt-merged  | 57           | paper-merged  | 29           | food-other-.. | 24           |
| building-ot.. | 152          |  rock-merged  | 22           | wall-other-.. | 145          |
|  rug-merged   | 14           |               |              |               |              |
|     total     | 7001         |               |              |               |              |[0m
[10/08 15:16:10] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 15:16:10] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 15:16:10] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 15:16:10] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 15:16:28] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0008 s/iter. Inference: 0.0510 s/iter. Eval: 0.0263 s/iter. Total: 0.0780 s/iter. ETA=0:00:18
[10/08 15:16:33] detectron2.evaluation.evaluator INFO: Inference done 76/250. Dataloading: 0.0014 s/iter. Inference: 0.0495 s/iter. Eval: 0.0275 s/iter. Total: 0.0785 s/iter. ETA=0:00:13
[10/08 15:16:38] detectron2.evaluation.evaluator INFO: Inference done 142/250. Dataloading: 0.0015 s/iter. Inference: 0.0486 s/iter. Eval: 0.0272 s/iter. Total: 0.0774 s/iter. ETA=0:00:08
[10/08 15:16:43] detectron2.evaluation.evaluator INFO: Inference done 210/250. Dataloading: 0.0016 s/iter. Inference: 0.0478 s/iter. Eval: 0.0270 s/iter. Total: 0.0764 s/iter. ETA=0:00:03
[10/08 15:16:46] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:19.135132 (0.078103 s / iter per device, on 2 devices)
[10/08 15:16:46] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.047731 s / iter per device, on 2 devices)
[10/08 15:17:18] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 15:38:30] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 15:38:30] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 15:38:30] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 15:38:30] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 15:38:48] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0026 s/iter. Inference: 0.0476 s/iter. Eval: 0.0229 s/iter. Total: 0.0731 s/iter. ETA=0:00:17
[10/08 15:38:53] detectron2.evaluation.evaluator INFO: Inference done 81/250. Dataloading: 0.0014 s/iter. Inference: 0.0447 s/iter. Eval: 0.0256 s/iter. Total: 0.0717 s/iter. ETA=0:00:12
[10/08 15:38:58] detectron2.evaluation.evaluator INFO: Inference done 148/250. Dataloading: 0.0014 s/iter. Inference: 0.0458 s/iter. Eval: 0.0261 s/iter. Total: 0.0734 s/iter. ETA=0:00:07
[10/08 15:39:03] detectron2.evaluation.evaluator INFO: Inference done 213/250. Dataloading: 0.0014 s/iter. Inference: 0.0466 s/iter. Eval: 0.0266 s/iter. Total: 0.0747 s/iter. ETA=0:00:02
[10/08 15:39:06] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:18.725136 (0.076429 s / iter per device, on 2 devices)
[10/08 15:39:06] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.046014 s / iter per device, on 2 devices)
[10/08 15:39:39] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 16:00:27] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 16:00:27] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 16:00:27] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 16:00:27] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 16:00:45] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0017 s/iter. Inference: 0.0525 s/iter. Eval: 0.0292 s/iter. Total: 0.0834 s/iter. ETA=0:00:19
[10/08 16:00:50] detectron2.evaluation.evaluator INFO: Inference done 69/250. Dataloading: 0.0021 s/iter. Inference: 0.0561 s/iter. Eval: 0.0292 s/iter. Total: 0.0874 s/iter. ETA=0:00:15
[10/08 16:00:55] detectron2.evaluation.evaluator INFO: Inference done 130/250. Dataloading: 0.0018 s/iter. Inference: 0.0541 s/iter. Eval: 0.0293 s/iter. Total: 0.0853 s/iter. ETA=0:00:10
[10/08 16:01:00] detectron2.evaluation.evaluator INFO: Inference done 185/250. Dataloading: 0.0019 s/iter. Inference: 0.0559 s/iter. Eval: 0.0294 s/iter. Total: 0.0873 s/iter. ETA=0:00:05
[10/08 16:01:06] detectron2.evaluation.evaluator INFO: Inference done 240/250. Dataloading: 0.0019 s/iter. Inference: 0.0569 s/iter. Eval: 0.0296 s/iter. Total: 0.0885 s/iter. ETA=0:00:00
[10/08 16:01:07] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:22.434645 (0.091570 s / iter per device, on 2 devices)
[10/08 16:01:07] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:13 (0.056864 s / iter per device, on 2 devices)
[10/08 16:01:39] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 16:23:12] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 16:23:12] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 16:23:12] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 16:23:12] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 16:23:30] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0020 s/iter. Inference: 0.0469 s/iter. Eval: 0.0256 s/iter. Total: 0.0745 s/iter. ETA=0:00:17
[10/08 16:23:36] detectron2.evaluation.evaluator INFO: Inference done 75/250. Dataloading: 0.0015 s/iter. Inference: 0.0497 s/iter. Eval: 0.0274 s/iter. Total: 0.0786 s/iter. ETA=0:00:13
[10/08 16:23:41] detectron2.evaluation.evaluator INFO: Inference done 140/250. Dataloading: 0.0020 s/iter. Inference: 0.0492 s/iter. Eval: 0.0268 s/iter. Total: 0.0781 s/iter. ETA=0:00:08
[10/08 16:23:46] detectron2.evaluation.evaluator INFO: Inference done 208/250. Dataloading: 0.0019 s/iter. Inference: 0.0480 s/iter. Eval: 0.0268 s/iter. Total: 0.0767 s/iter. ETA=0:00:03
[10/08 16:23:49] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:19.409780 (0.079224 s / iter per device, on 2 devices)
[10/08 16:23:49] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.047808 s / iter per device, on 2 devices)
[10/08 16:24:21] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 16:45:32] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 16:45:32] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 16:45:32] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 16:45:32] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 16:45:50] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0031 s/iter. Inference: 0.0557 s/iter. Eval: 0.0249 s/iter. Total: 0.0838 s/iter. ETA=0:00:20
[10/08 16:45:55] detectron2.evaluation.evaluator INFO: Inference done 74/250. Dataloading: 0.0017 s/iter. Inference: 0.0491 s/iter. Eval: 0.0289 s/iter. Total: 0.0798 s/iter. ETA=0:00:14
[10/08 16:46:00] detectron2.evaluation.evaluator INFO: Inference done 139/250. Dataloading: 0.0017 s/iter. Inference: 0.0489 s/iter. Eval: 0.0283 s/iter. Total: 0.0789 s/iter. ETA=0:00:08
[10/08 16:46:05] detectron2.evaluation.evaluator INFO: Inference done 208/250. Dataloading: 0.0016 s/iter. Inference: 0.0479 s/iter. Eval: 0.0273 s/iter. Total: 0.0769 s/iter. ETA=0:00:03
[10/08 16:46:09] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:19.291484 (0.078741 s / iter per device, on 2 devices)
[10/08 16:46:09] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.047483 s / iter per device, on 2 devices)
[10/08 16:46:43] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 17:07:48] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 17:07:48] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 17:07:48] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 17:07:48] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 17:08:06] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0011 s/iter. Inference: 0.0490 s/iter. Eval: 0.0237 s/iter. Total: 0.0739 s/iter. ETA=0:00:17
[10/08 17:08:11] detectron2.evaluation.evaluator INFO: Inference done 76/250. Dataloading: 0.0014 s/iter. Inference: 0.0473 s/iter. Eval: 0.0280 s/iter. Total: 0.0768 s/iter. ETA=0:00:13
[10/08 17:08:16] detectron2.evaluation.evaluator INFO: Inference done 141/250. Dataloading: 0.0015 s/iter. Inference: 0.0485 s/iter. Eval: 0.0273 s/iter. Total: 0.0773 s/iter. ETA=0:00:08
[10/08 17:08:21] detectron2.evaluation.evaluator INFO: Inference done 210/250. Dataloading: 0.0016 s/iter. Inference: 0.0474 s/iter. Eval: 0.0270 s/iter. Total: 0.0761 s/iter. ETA=0:00:03
[10/08 17:08:24] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:19.188039 (0.078319 s / iter per device, on 2 devices)
[10/08 17:08:24] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.047865 s / iter per device, on 2 devices)
[10/08 17:08:57] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 17:30:06] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 17:30:06] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 17:30:06] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 17:30:06] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 17:30:23] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0028 s/iter. Inference: 0.0526 s/iter. Eval: 0.0244 s/iter. Total: 0.0798 s/iter. ETA=0:00:19
[10/08 17:30:28] detectron2.evaluation.evaluator INFO: Inference done 75/250. Dataloading: 0.0015 s/iter. Inference: 0.0504 s/iter. Eval: 0.0264 s/iter. Total: 0.0784 s/iter. ETA=0:00:13
[10/08 17:30:33] detectron2.evaluation.evaluator INFO: Inference done 141/250. Dataloading: 0.0015 s/iter. Inference: 0.0494 s/iter. Eval: 0.0266 s/iter. Total: 0.0775 s/iter. ETA=0:00:08
[10/08 17:30:38] detectron2.evaluation.evaluator INFO: Inference done 211/250. Dataloading: 0.0016 s/iter. Inference: 0.0480 s/iter. Eval: 0.0262 s/iter. Total: 0.0759 s/iter. ETA=0:00:02
[10/08 17:30:42] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:18.981004 (0.077473 s / iter per device, on 2 devices)
[10/08 17:30:42] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.047265 s / iter per device, on 2 devices)
[10/08 17:31:14] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 17:54:04] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 17:54:04] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 17:54:04] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 17:54:04] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 17:54:22] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0012 s/iter. Inference: 0.0551 s/iter. Eval: 0.0258 s/iter. Total: 0.0821 s/iter. ETA=0:00:19
[10/08 17:54:27] detectron2.evaluation.evaluator INFO: Inference done 70/250. Dataloading: 0.0019 s/iter. Inference: 0.0549 s/iter. Eval: 0.0283 s/iter. Total: 0.0852 s/iter. ETA=0:00:15
[10/08 17:54:32] detectron2.evaluation.evaluator INFO: Inference done 129/250. Dataloading: 0.0020 s/iter. Inference: 0.0543 s/iter. Eval: 0.0288 s/iter. Total: 0.0852 s/iter. ETA=0:00:10
[10/08 17:54:37] detectron2.evaluation.evaluator INFO: Inference done 188/250. Dataloading: 0.0020 s/iter. Inference: 0.0542 s/iter. Eval: 0.0288 s/iter. Total: 0.0851 s/iter. ETA=0:00:05
[10/08 17:54:42] detectron2.evaluation.evaluator INFO: Inference done 248/250. Dataloading: 0.0020 s/iter. Inference: 0.0539 s/iter. Eval: 0.0288 s/iter. Total: 0.0848 s/iter. ETA=0:00:00
[10/08 17:54:43] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:21.456117 (0.087576 s / iter per device, on 2 devices)
[10/08 17:54:43] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:13 (0.054036 s / iter per device, on 2 devices)
[10/08 17:55:11] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 18:18:40] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 18:18:40] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 18:18:40] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 18:18:40] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 18:18:58] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0021 s/iter. Inference: 0.0626 s/iter. Eval: 0.0256 s/iter. Total: 0.0903 s/iter. ETA=0:00:21
[10/08 18:19:03] detectron2.evaluation.evaluator INFO: Inference done 64/250. Dataloading: 0.0017 s/iter. Inference: 0.0626 s/iter. Eval: 0.0308 s/iter. Total: 0.0953 s/iter. ETA=0:00:17
[10/08 18:19:08] detectron2.evaluation.evaluator INFO: Inference done 124/250. Dataloading: 0.0016 s/iter. Inference: 0.0581 s/iter. Eval: 0.0300 s/iter. Total: 0.0898 s/iter. ETA=0:00:11
[10/08 18:19:13] detectron2.evaluation.evaluator INFO: Inference done 185/250. Dataloading: 0.0018 s/iter. Inference: 0.0564 s/iter. Eval: 0.0292 s/iter. Total: 0.0875 s/iter. ETA=0:00:05
[10/08 18:19:18] detectron2.evaluation.evaluator INFO: Inference done 242/250. Dataloading: 0.0019 s/iter. Inference: 0.0563 s/iter. Eval: 0.0294 s/iter. Total: 0.0876 s/iter. ETA=0:00:00
[10/08 18:19:20] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:22.240024 (0.090776 s / iter per device, on 2 devices)
[10/08 18:19:20] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:13 (0.056577 s / iter per device, on 2 devices)
[10/08 18:19:46] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 18:42:46] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 18:42:46] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 18:42:46] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 18:42:46] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 18:43:04] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0015 s/iter. Inference: 0.0578 s/iter. Eval: 0.0257 s/iter. Total: 0.0850 s/iter. ETA=0:00:20
[10/08 18:43:09] detectron2.evaluation.evaluator INFO: Inference done 72/250. Dataloading: 0.0016 s/iter. Inference: 0.0522 s/iter. Eval: 0.0291 s/iter. Total: 0.0829 s/iter. ETA=0:00:14
[10/08 18:43:14] detectron2.evaluation.evaluator INFO: Inference done 135/250. Dataloading: 0.0018 s/iter. Inference: 0.0517 s/iter. Eval: 0.0281 s/iter. Total: 0.0817 s/iter. ETA=0:00:09
[10/08 18:43:19] detectron2.evaluation.evaluator INFO: Inference done 197/250. Dataloading: 0.0017 s/iter. Inference: 0.0515 s/iter. Eval: 0.0282 s/iter. Total: 0.0815 s/iter. ETA=0:00:04
[10/08 18:43:24] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:20.530622 (0.083798 s / iter per device, on 2 devices)
[10/08 18:43:24] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:12 (0.051167 s / iter per device, on 2 devices)
[10/08 18:43:52] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 19:06:12] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 19:06:12] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 19:06:12] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 19:06:12] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 19:06:30] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0032 s/iter. Inference: 0.0535 s/iter. Eval: 0.0289 s/iter. Total: 0.0856 s/iter. ETA=0:00:20
[10/08 19:06:35] detectron2.evaluation.evaluator INFO: Inference done 73/250. Dataloading: 0.0015 s/iter. Inference: 0.0524 s/iter. Eval: 0.0277 s/iter. Total: 0.0817 s/iter. ETA=0:00:14
[10/08 19:06:40] detectron2.evaluation.evaluator INFO: Inference done 133/250. Dataloading: 0.0018 s/iter. Inference: 0.0531 s/iter. Eval: 0.0276 s/iter. Total: 0.0825 s/iter. ETA=0:00:09
[10/08 19:06:45] detectron2.evaluation.evaluator INFO: Inference done 196/250. Dataloading: 0.0017 s/iter. Inference: 0.0521 s/iter. Eval: 0.0276 s/iter. Total: 0.0815 s/iter. ETA=0:00:04
[10/08 19:06:50] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:20.317311 (0.082928 s / iter per device, on 2 devices)
[10/08 19:06:50] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:12 (0.051282 s / iter per device, on 2 devices)
[10/08 19:07:23] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 19:30:12] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 19:30:12] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 19:30:12] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 19:30:12] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 19:30:30] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0295 s/iter. Total: 0.0986 s/iter. ETA=0:00:23
[10/08 19:30:35] detectron2.evaluation.evaluator INFO: Inference done 64/250. Dataloading: 0.0016 s/iter. Inference: 0.0642 s/iter. Eval: 0.0293 s/iter. Total: 0.0952 s/iter. ETA=0:00:17
[10/08 19:30:40] detectron2.evaluation.evaluator INFO: Inference done 123/250. Dataloading: 0.0016 s/iter. Inference: 0.0590 s/iter. Eval: 0.0295 s/iter. Total: 0.0902 s/iter. ETA=0:00:11
[10/08 19:30:45] detectron2.evaluation.evaluator INFO: Inference done 181/250. Dataloading: 0.0017 s/iter. Inference: 0.0579 s/iter. Eval: 0.0297 s/iter. Total: 0.0894 s/iter. ETA=0:00:06
[10/08 19:30:50] detectron2.evaluation.evaluator INFO: Inference done 242/250. Dataloading: 0.0017 s/iter. Inference: 0.0567 s/iter. Eval: 0.0292 s/iter. Total: 0.0876 s/iter. ETA=0:00:00
[10/08 19:30:51] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:21.990044 (0.089755 s / iter per device, on 2 devices)
[10/08 19:30:51] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:13 (0.056581 s / iter per device, on 2 devices)
[10/08 19:31:23] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 19:54:22] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 19:54:22] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 19:54:22] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 19:54:22] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 19:54:40] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0012 s/iter. Inference: 0.0440 s/iter. Eval: 0.0260 s/iter. Total: 0.0712 s/iter. ETA=0:00:17
[10/08 19:54:45] detectron2.evaluation.evaluator INFO: Inference done 68/250. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.0299 s/iter. Total: 0.0872 s/iter. ETA=0:00:15
[10/08 19:54:50] detectron2.evaluation.evaluator INFO: Inference done 122/250. Dataloading: 0.0018 s/iter. Inference: 0.0570 s/iter. Eval: 0.0309 s/iter. Total: 0.0898 s/iter. ETA=0:00:11
[10/08 19:54:55] detectron2.evaluation.evaluator INFO: Inference done 181/250. Dataloading: 0.0018 s/iter. Inference: 0.0566 s/iter. Eval: 0.0301 s/iter. Total: 0.0885 s/iter. ETA=0:00:06
[10/08 19:55:00] detectron2.evaluation.evaluator INFO: Inference done 237/250. Dataloading: 0.0018 s/iter. Inference: 0.0570 s/iter. Eval: 0.0299 s/iter. Total: 0.0888 s/iter. ETA=0:00:01
[10/08 19:55:02] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:22.367213 (0.091295 s / iter per device, on 2 devices)
[10/08 19:55:02] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:14 (0.057278 s / iter per device, on 2 devices)
[10/08 19:55:34] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 20:18:33] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 20:18:33] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 20:18:33] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 20:18:33] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 20:18:52] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0018 s/iter. Inference: 0.0518 s/iter. Eval: 0.0307 s/iter. Total: 0.0842 s/iter. ETA=0:00:20
[10/08 20:18:57] detectron2.evaluation.evaluator INFO: Inference done 68/250. Dataloading: 0.0021 s/iter. Inference: 0.0561 s/iter. Eval: 0.0295 s/iter. Total: 0.0877 s/iter. ETA=0:00:15
[10/08 20:19:02] detectron2.evaluation.evaluator INFO: Inference done 123/250. Dataloading: 0.0021 s/iter. Inference: 0.0576 s/iter. Eval: 0.0295 s/iter. Total: 0.0893 s/iter. ETA=0:00:11
[10/08 20:19:07] detectron2.evaluation.evaluator INFO: Inference done 182/250. Dataloading: 0.0022 s/iter. Inference: 0.0568 s/iter. Eval: 0.0293 s/iter. Total: 0.0883 s/iter. ETA=0:00:06
[10/08 20:19:12] detectron2.evaluation.evaluator INFO: Inference done 238/250. Dataloading: 0.0022 s/iter. Inference: 0.0574 s/iter. Eval: 0.0290 s/iter. Total: 0.0886 s/iter. ETA=0:00:01
[10/08 20:19:14] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:22.120084 (0.090286 s / iter per device, on 2 devices)
[10/08 20:19:14] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:13 (0.056934 s / iter per device, on 2 devices)
[10/08 20:19:42] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 20:41:11] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 20:41:11] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 20:41:11] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 20:41:11] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 20:41:27] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0023 s/iter. Inference: 0.0439 s/iter. Eval: 0.0281 s/iter. Total: 0.0743 s/iter. ETA=0:00:17
[10/08 20:41:32] detectron2.evaluation.evaluator INFO: Inference done 75/250. Dataloading: 0.0019 s/iter. Inference: 0.0478 s/iter. Eval: 0.0286 s/iter. Total: 0.0783 s/iter. ETA=0:00:13
[10/08 20:41:37] detectron2.evaluation.evaluator INFO: Inference done 142/250. Dataloading: 0.0025 s/iter. Inference: 0.0464 s/iter. Eval: 0.0277 s/iter. Total: 0.0767 s/iter. ETA=0:00:08
[10/08 20:41:42] detectron2.evaluation.evaluator INFO: Inference done 210/250. Dataloading: 0.0026 s/iter. Inference: 0.0453 s/iter. Eval: 0.0277 s/iter. Total: 0.0757 s/iter. ETA=0:00:03
[10/08 20:41:45] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:18.971066 (0.077433 s / iter per device, on 2 devices)
[10/08 20:41:45] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.045053 s / iter per device, on 2 devices)
[10/08 20:42:14] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 21:03:25] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 21:03:25] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 21:03:25] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 21:03:25] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 21:03:42] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0023 s/iter. Inference: 0.0461 s/iter. Eval: 0.0262 s/iter. Total: 0.0746 s/iter. ETA=0:00:17
[10/08 21:03:47] detectron2.evaluation.evaluator INFO: Inference done 78/250. Dataloading: 0.0014 s/iter. Inference: 0.0484 s/iter. Eval: 0.0256 s/iter. Total: 0.0755 s/iter. ETA=0:00:12
[10/08 21:03:52] detectron2.evaluation.evaluator INFO: Inference done 143/250. Dataloading: 0.0018 s/iter. Inference: 0.0479 s/iter. Eval: 0.0267 s/iter. Total: 0.0765 s/iter. ETA=0:00:08
[10/08 21:03:57] detectron2.evaluation.evaluator INFO: Inference done 211/250. Dataloading: 0.0019 s/iter. Inference: 0.0470 s/iter. Eval: 0.0270 s/iter. Total: 0.0759 s/iter. ETA=0:00:02
[10/08 21:04:01] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:19.106243 (0.077985 s / iter per device, on 2 devices)
[10/08 21:04:01] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.046698 s / iter per device, on 2 devices)
[10/08 21:04:33] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 21:25:16] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 21:25:16] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 21:25:16] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 21:25:16] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 21:25:33] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0039 s/iter. Inference: 0.0438 s/iter. Eval: 0.0269 s/iter. Total: 0.0746 s/iter. ETA=0:00:17
[10/08 21:25:38] detectron2.evaluation.evaluator INFO: Inference done 75/250. Dataloading: 0.0019 s/iter. Inference: 0.0465 s/iter. Eval: 0.0294 s/iter. Total: 0.0779 s/iter. ETA=0:00:13
[10/08 21:25:43] detectron2.evaluation.evaluator INFO: Inference done 140/250. Dataloading: 0.0019 s/iter. Inference: 0.0468 s/iter. Eval: 0.0287 s/iter. Total: 0.0775 s/iter. ETA=0:00:08
[10/08 21:25:48] detectron2.evaluation.evaluator INFO: Inference done 209/250. Dataloading: 0.0020 s/iter. Inference: 0.0456 s/iter. Eval: 0.0284 s/iter. Total: 0.0760 s/iter. ETA=0:00:03
[10/08 21:25:51] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:19.149351 (0.078161 s / iter per device, on 2 devices)
[10/08 21:25:51] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.045079 s / iter per device, on 2 devices)
[10/08 21:26:19] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 21:47:04] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 21:47:04] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 21:47:04] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 21:47:04] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 21:47:23] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0025 s/iter. Inference: 0.0571 s/iter. Eval: 0.0260 s/iter. Total: 0.0856 s/iter. ETA=0:00:20
[10/08 21:47:28] detectron2.evaluation.evaluator INFO: Inference done 70/250. Dataloading: 0.0026 s/iter. Inference: 0.0537 s/iter. Eval: 0.0287 s/iter. Total: 0.0851 s/iter. ETA=0:00:15
[10/08 21:47:33] detectron2.evaluation.evaluator INFO: Inference done 129/250. Dataloading: 0.0028 s/iter. Inference: 0.0535 s/iter. Eval: 0.0290 s/iter. Total: 0.0854 s/iter. ETA=0:00:10
[10/08 21:47:38] detectron2.evaluation.evaluator INFO: Inference done 193/250. Dataloading: 0.0027 s/iter. Inference: 0.0521 s/iter. Eval: 0.0283 s/iter. Total: 0.0831 s/iter. ETA=0:00:04
[10/08 21:47:43] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:20.618865 (0.084159 s / iter per device, on 2 devices)
[10/08 21:47:43] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:12 (0.050500 s / iter per device, on 2 devices)
[10/08 21:48:18] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 22:08:58] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 22:08:58] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 22:08:58] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 22:08:58] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 22:09:14] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0019 s/iter. Inference: 0.0450 s/iter. Eval: 0.0335 s/iter. Total: 0.0804 s/iter. ETA=0:00:19
[10/08 22:09:19] detectron2.evaluation.evaluator INFO: Inference done 73/250. Dataloading: 0.0014 s/iter. Inference: 0.0509 s/iter. Eval: 0.0284 s/iter. Total: 0.0807 s/iter. ETA=0:00:14
[10/08 22:09:24] detectron2.evaluation.evaluator INFO: Inference done 141/250. Dataloading: 0.0014 s/iter. Inference: 0.0482 s/iter. Eval: 0.0280 s/iter. Total: 0.0776 s/iter. ETA=0:00:08
[10/08 22:09:29] detectron2.evaluation.evaluator INFO: Inference done 210/250. Dataloading: 0.0014 s/iter. Inference: 0.0468 s/iter. Eval: 0.0276 s/iter. Total: 0.0759 s/iter. ETA=0:00:03
[10/08 22:09:33] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:19.196061 (0.078351 s / iter per device, on 2 devices)
[10/08 22:09:33] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.046866 s / iter per device, on 2 devices)
[10/08 22:10:01] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 22:31:11] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 22:31:11] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 22:31:11] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 22:31:11] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 22:31:29] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0021 s/iter. Inference: 0.0466 s/iter. Eval: 0.0276 s/iter. Total: 0.0764 s/iter. ETA=0:00:18
[10/08 22:31:34] detectron2.evaluation.evaluator INFO: Inference done 76/250. Dataloading: 0.0014 s/iter. Inference: 0.0483 s/iter. Eval: 0.0275 s/iter. Total: 0.0773 s/iter. ETA=0:00:13
[10/08 22:31:39] detectron2.evaluation.evaluator INFO: Inference done 144/250. Dataloading: 0.0014 s/iter. Inference: 0.0470 s/iter. Eval: 0.0276 s/iter. Total: 0.0761 s/iter. ETA=0:00:08
[10/08 22:31:44] detectron2.evaluation.evaluator INFO: Inference done 210/250. Dataloading: 0.0016 s/iter. Inference: 0.0472 s/iter. Eval: 0.0275 s/iter. Total: 0.0763 s/iter. ETA=0:00:03
[10/08 22:31:48] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:19.091652 (0.077925 s / iter per device, on 2 devices)
[10/08 22:31:48] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:11 (0.046721 s / iter per device, on 2 devices)
[10/08 22:32:14] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/08 22:53:15] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/08 22:53:15] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/08 22:53:15] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/08 22:53:15] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/08 22:57:29] detectron2.engine.hooks INFO: Overall training speed: 41997 iterations in 7:35:18 (0.6505 s / it)
[10/08 22:57:29] detectron2.engine.hooks INFO: Total training time: 8:02:33 (0:27:15 on hooks)
