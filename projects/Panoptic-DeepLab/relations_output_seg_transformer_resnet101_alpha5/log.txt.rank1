[10/10 10:16:04] detectron2 INFO: Rank of current process: 1. World size: 2
[10/10 10:16:05] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/autodl-tmp/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 10:16:05] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/10 10:16:05] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-103.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "./relations_output_seg_transformer_resnet101/model_best.pth"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m101
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m5.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mALPHA[39m[38;5;15m:[39m[38;5;15m [39m5.0
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m20000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet101_alpha5[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m

[10/10 10:16:05] detectron2.utils.env INFO: Using a generated random seed 6035915
[10/10 10:16:09] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res3): Linear(in_features=512, out_features=256, bias=True)
      (res5): Linear(in_features=2048, out_features=256, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.3, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.3, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.3, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.3, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.3, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.3, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.3, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.3, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.3, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.3, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.3, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.3, inplace=False)
          )
        )
      )
      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.3, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=256, out_features=512, bias=True)
      (attn_drop): Dropout(p=0.3, inplace=False)
      (proj_cls): Linear(in_features=256, out_features=256, bias=True)
      (proj_rel): Linear(in_features=256, out_features=256, bias=True)
      (proj_drop): Dropout(p=0.3, inplace=False)
    )
    (cls_fc): Linear(in_features=256, out_features=1, bias=True)
    (rel_fc): Linear(in_features=256, out_features=1, bias=True)
  )
)
[10/10 10:16:09] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/10 10:16:10] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/10 10:16:10] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/10 10:16:10] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/10 10:16:10] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/10 10:16:10] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/10 10:16:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-103.pkl ...
[10/10 10:16:10] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/10 10:16:11] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4.10.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4.10.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4.10.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4.11.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4.11.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4.11.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4.12.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4.12.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4.12.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4.13.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4.13.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4.13.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4.14.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4.14.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4.14.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4.15.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4.15.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4.15.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4.16.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4.16.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4.16.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4.17.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4.17.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4.17.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4.18.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4.18.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4.18.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4.19.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4.19.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4.19.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4.20.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4.20.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4.20.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4.21.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4.21.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4.21.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4.22.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4.22.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4.22.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4.6.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4.6.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4.6.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4.7.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4.7.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4.7.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4.8.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4.8.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4.8.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4.9.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4.9.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4.9.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/10 10:16:11] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.2.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.3.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/10 10:16:11] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.10.conv1.norm.num_batches_tracked[0m
  [35mres4.10.conv2.norm.num_batches_tracked[0m
  [35mres4.10.conv3.norm.num_batches_tracked[0m
  [35mres4.11.conv1.norm.num_batches_tracked[0m
  [35mres4.11.conv2.norm.num_batches_tracked[0m
  [35mres4.11.conv3.norm.num_batches_tracked[0m
  [35mres4.12.conv1.norm.num_batches_tracked[0m
  [35mres4.12.conv2.norm.num_batches_tracked[0m
  [35mres4.12.conv3.norm.num_batches_tracked[0m
  [35mres4.13.conv1.norm.num_batches_tracked[0m
  [35mres4.13.conv2.norm.num_batches_tracked[0m
  [35mres4.13.conv3.norm.num_batches_tracked[0m
  [35mres4.14.conv1.norm.num_batches_tracked[0m
  [35mres4.14.conv2.norm.num_batches_tracked[0m
  [35mres4.14.conv3.norm.num_batches_tracked[0m
  [35mres4.15.conv1.norm.num_batches_tracked[0m
  [35mres4.15.conv2.norm.num_batches_tracked[0m
  [35mres4.15.conv3.norm.num_batches_tracked[0m
  [35mres4.16.conv1.norm.num_batches_tracked[0m
  [35mres4.16.conv2.norm.num_batches_tracked[0m
  [35mres4.16.conv3.norm.num_batches_tracked[0m
  [35mres4.17.conv1.norm.num_batches_tracked[0m
  [35mres4.17.conv2.norm.num_batches_tracked[0m
  [35mres4.17.conv3.norm.num_batches_tracked[0m
  [35mres4.18.conv1.norm.num_batches_tracked[0m
  [35mres4.18.conv2.norm.num_batches_tracked[0m
  [35mres4.18.conv3.norm.num_batches_tracked[0m
  [35mres4.19.conv1.norm.num_batches_tracked[0m
  [35mres4.19.conv2.norm.num_batches_tracked[0m
  [35mres4.19.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.20.conv1.norm.num_batches_tracked[0m
  [35mres4.20.conv2.norm.num_batches_tracked[0m
  [35mres4.20.conv3.norm.num_batches_tracked[0m
  [35mres4.21.conv1.norm.num_batches_tracked[0m
  [35mres4.21.conv2.norm.num_batches_tracked[0m
  [35mres4.21.conv3.norm.num_batches_tracked[0m
  [35mres4.22.conv1.norm.num_batches_tracked[0m
  [35mres4.22.conv2.norm.num_batches_tracked[0m
  [35mres4.22.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres4.6.conv1.norm.num_batches_tracked[0m
  [35mres4.6.conv2.norm.num_batches_tracked[0m
  [35mres4.6.conv3.norm.num_batches_tracked[0m
  [35mres4.7.conv1.norm.num_batches_tracked[0m
  [35mres4.7.conv2.norm.num_batches_tracked[0m
  [35mres4.7.conv3.norm.num_batches_tracked[0m
  [35mres4.8.conv1.norm.num_batches_tracked[0m
  [35mres4.8.conv2.norm.num_batches_tracked[0m
  [35mres4.8.conv3.norm.num_batches_tracked[0m
  [35mres4.9.conv1.norm.num_batches_tracked[0m
  [35mres4.9.conv2.norm.num_batches_tracked[0m
  [35mres4.9.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/10 10:16:11] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/10 10:39:59] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 1980         |    bicycle    | 80           |      car      | 332          |
|  motorcycle   | 51           |   airplane    | 15           |      bus      | 38           |
|     train     | 21           |     truck     | 70           |     boat      | 53           |
| traffic light | 93           | fire hydrant  | 9            |   stop sign   | 8            |
| parking meter | 1            |     bench     | 56           |     bird      | 86           |
|      cat      | 8            |      dog      | 18           |     horse     | 42           |
|     sheep     | 47           |      cow      | 30           |   elephant    | 29           |
|     bear      | 10           |     zebra     | 47           |    giraffe    | 33           |
|   backpack    | 55           |   umbrella    | 44           |    handbag    | 130          |
|      tie      | 33           |   suitcase    | 18           |    frisbee    | 7            |
|     skis      | 44           |   snowboard   | 11           |  sports ball  | 46           |
|     kite      | 94           | baseball bat  | 24           | baseball gl.. | 32           |
|  skateboard   | 37           |   surfboard   | 55           | tennis racket | 30           |
|    bottle     | 77           |  wine glass   | 41           |      cup      | 104          |
|     fork      | 23           |     knife     | 30           |     spoon     | 23           |
|     bowl      | 51           |    banana     | 52           |     apple     | 14           |
|   sandwich    | 5            |    orange     | 13           |   broccoli    | 3            |
|    carrot     | 16           |    hot dog    | 8            |     pizza     | 14           |
|     donut     | 9            |     cake      | 15           |     chair     | 197          |
|     couch     | 17           | potted plant  | 10           |      bed      | 10           |
| dining table  | 45           |    toilet     | 6            |      tv       | 12           |
|    laptop     | 16           |     mouse     | 2            |    remote     | 23           |
|   keyboard    | 2            |  cell phone   | 25           |   microwave   | 0            |
|     oven      | 3            |    toaster    | 0            |     sink      | 7            |
| refrigerator  | 2            |     book      | 74           |     clock     | 11           |
|     vase      | 1            |   scissors    | 0            |  teddy bear   | 33           |
|  hair drier   | 0            |  toothbrush   | 8            |    banner     | 29           |
|    blanket    | 13           |    bridge     | 9            |   cardboard   | 14           |
|    counter    | 7            |    curtain    | 12           |  door-stuff   | 30           |
|  floor-wood   | 16           |    flower     | 9            |     fruit     | 6            |
|    gravel     | 10           |     house     | 33           |     light     | 41           |
| mirror-stuff  | 7            |      net      | 7            |    pillow     | 7            |
|   platform    | 16           | playingfield  | 39           |   railroad    | 17           |
|     river     | 10           |     road      | 101          |     roof      | 20           |
|     sand      | 28           |      sea      | 53           |     shelf     | 19           |
|     snow      | 27           |    stairs     | 16           |     tent      | 11           |
|     towel     | 12           |  wall-brick   | 24           |  wall-stone   | 15           |
|   wall-tile   | 12           |   wall-wood   | 34           |  water-other  | 10           |
| window-blind  | 8            | window-other  | 40           |  tree-merged  | 224          |
| fence-merged  | 91           | ceiling-mer.. | 32           | sky-other-m.. | 233          |
| cabinet-mer.. | 16           | table-merged  | 46           | floor-other.. | 42           |
| pavement-me.. | 134          | mountain-me.. | 31           | grass-merged  | 128          |
|  dirt-merged  | 57           | paper-merged  | 29           | food-other-.. | 24           |
| building-ot.. | 152          |  rock-merged  | 22           | wall-other-.. | 145          |
|  rug-merged   | 14           |               |              |               |              |
|     total     | 7001         |               |              |               |              |[0m
[10/10 10:39:59] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/10 10:39:59] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/10 10:39:59] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/10 10:39:59] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/10 10:40:13] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0012 s/iter. Inference: 0.0859 s/iter. Eval: 0.0261 s/iter. Total: 0.1132 s/iter. ETA=0:00:27
[10/10 10:40:18] detectron2.evaluation.evaluator INFO: Inference done 53/250. Dataloading: 0.0014 s/iter. Inference: 0.0915 s/iter. Eval: 0.0272 s/iter. Total: 0.1201 s/iter. ETA=0:00:23
[10/10 10:40:23] detectron2.evaluation.evaluator INFO: Inference done 95/250. Dataloading: 0.0014 s/iter. Inference: 0.0916 s/iter. Eval: 0.0278 s/iter. Total: 0.1209 s/iter. ETA=0:00:18
[10/10 10:40:28] detectron2.evaluation.evaluator INFO: Inference done 138/250. Dataloading: 0.0015 s/iter. Inference: 0.0905 s/iter. Eval: 0.0276 s/iter. Total: 0.1197 s/iter. ETA=0:00:13
[10/10 10:40:33] detectron2.evaluation.evaluator INFO: Inference done 181/250. Dataloading: 0.0015 s/iter. Inference: 0.0905 s/iter. Eval: 0.0275 s/iter. Total: 0.1195 s/iter. ETA=0:00:08
[10/10 10:40:38] detectron2.evaluation.evaluator INFO: Inference done 224/250. Dataloading: 0.0015 s/iter. Inference: 0.0900 s/iter. Eval: 0.0273 s/iter. Total: 0.1189 s/iter. ETA=0:00:03
[10/10 10:40:42] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:29.249079 (0.119384 s / iter per device, on 2 devices)
[10/10 10:40:42] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:21 (0.089202 s / iter per device, on 2 devices)
[10/10 10:40:47] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/10 11:04:15] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/10 11:04:15] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/10 11:04:15] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/10 11:04:15] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/10 11:04:30] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0022 s/iter. Inference: 0.0901 s/iter. Eval: 0.0264 s/iter. Total: 0.1188 s/iter. ETA=0:00:28
[10/10 11:04:35] detectron2.evaluation.evaluator INFO: Inference done 53/250. Dataloading: 0.0012 s/iter. Inference: 0.0915 s/iter. Eval: 0.0268 s/iter. Total: 0.1196 s/iter. ETA=0:00:23
[10/10 11:04:40] detectron2.evaluation.evaluator INFO: Inference done 94/250. Dataloading: 0.0013 s/iter. Inference: 0.0929 s/iter. Eval: 0.0277 s/iter. Total: 0.1220 s/iter. ETA=0:00:19
[10/10 11:04:45] detectron2.evaluation.evaluator INFO: Inference done 136/250. Dataloading: 0.0014 s/iter. Inference: 0.0923 s/iter. Eval: 0.0274 s/iter. Total: 0.1211 s/iter. ETA=0:00:13
[10/10 11:04:50] detectron2.evaluation.evaluator INFO: Inference done 178/250. Dataloading: 0.0014 s/iter. Inference: 0.0923 s/iter. Eval: 0.0273 s/iter. Total: 0.1210 s/iter. ETA=0:00:08
[10/10 11:04:55] detectron2.evaluation.evaluator INFO: Inference done 221/250. Dataloading: 0.0014 s/iter. Inference: 0.0919 s/iter. Eval: 0.0271 s/iter. Total: 0.1205 s/iter. ETA=0:00:03
[10/10 11:04:59] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:29.696447 (0.121210 s / iter per device, on 2 devices)
[10/10 11:04:59] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:22 (0.091299 s / iter per device, on 2 devices)
[10/10 11:05:04] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/10 11:28:31] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/10 11:28:31] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/10 11:28:31] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/10 11:28:31] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/10 11:28:46] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0024 s/iter. Inference: 0.0849 s/iter. Eval: 0.0263 s/iter. Total: 0.1136 s/iter. ETA=0:00:27
[10/10 11:28:51] detectron2.evaluation.evaluator INFO: Inference done 53/250. Dataloading: 0.0017 s/iter. Inference: 0.0904 s/iter. Eval: 0.0271 s/iter. Total: 0.1193 s/iter. ETA=0:00:23
[10/10 11:28:56] detectron2.evaluation.evaluator INFO: Inference done 95/250. Dataloading: 0.0016 s/iter. Inference: 0.0908 s/iter. Eval: 0.0277 s/iter. Total: 0.1201 s/iter. ETA=0:00:18
[10/10 11:29:01] detectron2.evaluation.evaluator INFO: Inference done 137/250. Dataloading: 0.0016 s/iter. Inference: 0.0908 s/iter. Eval: 0.0274 s/iter. Total: 0.1198 s/iter. ETA=0:00:13
[10/10 11:29:06] detectron2.evaluation.evaluator INFO: Inference done 179/250. Dataloading: 0.0016 s/iter. Inference: 0.0908 s/iter. Eval: 0.0273 s/iter. Total: 0.1197 s/iter. ETA=0:00:08
[10/10 11:29:11] detectron2.evaluation.evaluator INFO: Inference done 224/250. Dataloading: 0.0015 s/iter. Inference: 0.0898 s/iter. Eval: 0.0271 s/iter. Total: 0.1184 s/iter. ETA=0:00:03
[10/10 11:29:14] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:29.146819 (0.118967 s / iter per device, on 2 devices)
[10/10 11:29:14] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:21 (0.089004 s / iter per device, on 2 devices)
[10/10 11:29:20] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/10 11:52:47] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/10 11:52:47] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/10 11:52:47] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/10 11:52:47] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/10 11:53:01] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0006 s/iter. Inference: 0.0903 s/iter. Eval: 0.0256 s/iter. Total: 0.1165 s/iter. ETA=0:00:27
[10/10 11:53:06] detectron2.evaluation.evaluator INFO: Inference done 53/250. Dataloading: 0.0015 s/iter. Inference: 0.0916 s/iter. Eval: 0.0275 s/iter. Total: 0.1206 s/iter. ETA=0:00:23
[10/10 11:53:11] detectron2.evaluation.evaluator INFO: Inference done 94/250. Dataloading: 0.0015 s/iter. Inference: 0.0924 s/iter. Eval: 0.0279 s/iter. Total: 0.1219 s/iter. ETA=0:00:19
[10/10 11:53:16] detectron2.evaluation.evaluator INFO: Inference done 137/250. Dataloading: 0.0015 s/iter. Inference: 0.0913 s/iter. Eval: 0.0275 s/iter. Total: 0.1204 s/iter. ETA=0:00:13
[10/10 11:53:21] detectron2.evaluation.evaluator INFO: Inference done 180/250. Dataloading: 0.0015 s/iter. Inference: 0.0911 s/iter. Eval: 0.0273 s/iter. Total: 0.1200 s/iter. ETA=0:00:08
[10/10 11:53:26] detectron2.evaluation.evaluator INFO: Inference done 222/250. Dataloading: 0.0015 s/iter. Inference: 0.0910 s/iter. Eval: 0.0273 s/iter. Total: 0.1199 s/iter. ETA=0:00:03
[10/10 11:53:30] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:29.536533 (0.120557 s / iter per device, on 2 devices)
[10/10 11:53:30] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:22 (0.090343 s / iter per device, on 2 devices)
[10/10 11:53:35] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/10 12:17:02] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/10 12:17:02] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/10 12:17:02] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/10 12:17:02] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/10 12:17:16] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0016 s/iter. Inference: 0.0902 s/iter. Eval: 0.0265 s/iter. Total: 0.1183 s/iter. ETA=0:00:28
[10/10 12:17:21] detectron2.evaluation.evaluator INFO: Inference done 52/250. Dataloading: 0.0012 s/iter. Inference: 0.0935 s/iter. Eval: 0.0272 s/iter. Total: 0.1220 s/iter. ETA=0:00:24
[10/10 12:17:26] detectron2.evaluation.evaluator INFO: Inference done 94/250. Dataloading: 0.0013 s/iter. Inference: 0.0929 s/iter. Eval: 0.0278 s/iter. Total: 0.1220 s/iter. ETA=0:00:19
[10/10 12:17:31] detectron2.evaluation.evaluator INFO: Inference done 136/250. Dataloading: 0.0014 s/iter. Inference: 0.0922 s/iter. Eval: 0.0274 s/iter. Total: 0.1211 s/iter. ETA=0:00:13
[10/10 12:17:36] detectron2.evaluation.evaluator INFO: Inference done 177/250. Dataloading: 0.0015 s/iter. Inference: 0.0925 s/iter. Eval: 0.0274 s/iter. Total: 0.1214 s/iter. ETA=0:00:08
[10/10 12:17:41] detectron2.evaluation.evaluator INFO: Inference done 220/250. Dataloading: 0.0015 s/iter. Inference: 0.0920 s/iter. Eval: 0.0273 s/iter. Total: 0.1208 s/iter. ETA=0:00:03
[10/10 12:17:45] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:29.733377 (0.121361 s / iter per device, on 2 devices)
[10/10 12:17:45] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:22 (0.091343 s / iter per device, on 2 devices)
[10/10 12:17:50] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/10 12:41:25] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/10 12:41:25] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/10 12:41:25] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/10 12:41:25] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/10 12:41:40] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0012 s/iter. Inference: 0.0971 s/iter. Eval: 0.0259 s/iter. Total: 0.1241 s/iter. ETA=0:00:29
[10/10 12:41:46] detectron2.evaluation.evaluator INFO: Inference done 52/250. Dataloading: 0.0011 s/iter. Inference: 0.0973 s/iter. Eval: 0.0270 s/iter. Total: 0.1255 s/iter. ETA=0:00:24
[10/10 12:41:51] detectron2.evaluation.evaluator INFO: Inference done 92/250. Dataloading: 0.0013 s/iter. Inference: 0.0971 s/iter. Eval: 0.0276 s/iter. Total: 0.1260 s/iter. ETA=0:00:19
[10/10 12:41:56] detectron2.evaluation.evaluator INFO: Inference done 133/250. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0274 s/iter. Total: 0.1248 s/iter. ETA=0:00:14
[10/10 12:42:01] detectron2.evaluation.evaluator INFO: Inference done 173/250. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0274 s/iter. Total: 0.1250 s/iter. ETA=0:00:09
[10/10 12:42:06] detectron2.evaluation.evaluator INFO: Inference done 215/250. Dataloading: 0.0014 s/iter. Inference: 0.0951 s/iter. Eval: 0.0273 s/iter. Total: 0.1238 s/iter. ETA=0:00:04
[10/10 12:42:10] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:30.477499 (0.124398 s / iter per device, on 2 devices)
[10/10 12:42:10] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:23 (0.094204 s / iter per device, on 2 devices)
[10/10 12:42:15] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/10 13:05:50] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/10 13:05:50] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/10 13:05:50] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/10 13:05:50] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/10 13:06:05] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0021 s/iter. Inference: 0.0917 s/iter. Eval: 0.0259 s/iter. Total: 0.1198 s/iter. ETA=0:00:28
[10/10 13:06:10] detectron2.evaluation.evaluator INFO: Inference done 52/250. Dataloading: 0.0013 s/iter. Inference: 0.0938 s/iter. Eval: 0.0270 s/iter. Total: 0.1222 s/iter. ETA=0:00:24
[10/10 13:06:15] detectron2.evaluation.evaluator INFO: Inference done 92/250. Dataloading: 0.0014 s/iter. Inference: 0.0949 s/iter. Eval: 0.0276 s/iter. Total: 0.1239 s/iter. ETA=0:00:19
[10/10 13:06:20] detectron2.evaluation.evaluator INFO: Inference done 135/250. Dataloading: 0.0014 s/iter. Inference: 0.0934 s/iter. Eval: 0.0273 s/iter. Total: 0.1223 s/iter. ETA=0:00:14
[10/10 13:06:25] detectron2.evaluation.evaluator INFO: Inference done 177/250. Dataloading: 0.0015 s/iter. Inference: 0.0931 s/iter. Eval: 0.0273 s/iter. Total: 0.1220 s/iter. ETA=0:00:08
[10/10 13:06:30] detectron2.evaluation.evaluator INFO: Inference done 220/250. Dataloading: 0.0014 s/iter. Inference: 0.0923 s/iter. Eval: 0.0271 s/iter. Total: 0.1209 s/iter. ETA=0:00:03
[10/10 13:06:34] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:29.765725 (0.121493 s / iter per device, on 2 devices)
[10/10 13:06:34] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:22 (0.091507 s / iter per device, on 2 devices)
[10/10 13:06:39] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/10 13:30:07] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/10 13:30:07] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/10 13:30:07] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/10 13:30:07] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/10 13:30:21] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0012 s/iter. Inference: 0.0871 s/iter. Eval: 0.0254 s/iter. Total: 0.1137 s/iter. ETA=0:00:27
[10/10 13:30:26] detectron2.evaluation.evaluator INFO: Inference done 52/250. Dataloading: 0.0014 s/iter. Inference: 0.0927 s/iter. Eval: 0.0272 s/iter. Total: 0.1214 s/iter. ETA=0:00:24
[10/10 13:30:31] detectron2.evaluation.evaluator INFO: Inference done 93/250. Dataloading: 0.0014 s/iter. Inference: 0.0935 s/iter. Eval: 0.0275 s/iter. Total: 0.1225 s/iter. ETA=0:00:19
[10/10 13:30:36] detectron2.evaluation.evaluator INFO: Inference done 135/250. Dataloading: 0.0014 s/iter. Inference: 0.0928 s/iter. Eval: 0.0272 s/iter. Total: 0.1215 s/iter. ETA=0:00:13
[10/10 13:30:41] detectron2.evaluation.evaluator INFO: Inference done 177/250. Dataloading: 0.0015 s/iter. Inference: 0.0927 s/iter. Eval: 0.0272 s/iter. Total: 0.1214 s/iter. ETA=0:00:08
[10/10 13:30:46] detectron2.evaluation.evaluator INFO: Inference done 220/250. Dataloading: 0.0015 s/iter. Inference: 0.0921 s/iter. Eval: 0.0271 s/iter. Total: 0.1207 s/iter. ETA=0:00:03
[10/10 13:30:50] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:29.680095 (0.121143 s / iter per device, on 2 devices)
[10/10 13:30:50] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:22 (0.091327 s / iter per device, on 2 devices)
[10/10 13:30:55] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
[10/10 13:42:28] detectron2.engine.hooks INFO: Overall training speed: 8490 iterations in 3:19:21 (1.4090 s / it)
[10/10 13:42:28] detectron2.engine.hooks INFO: Total training time: 3:25:59 (0:06:37 on hooks)
[10/10 13:42:55] detectron2 INFO: Rank of current process: 1. World size: 2
[10/10 13:42:56] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
numpy                   1.23.3
detectron2              0.6 @/root/autodl-tmp/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  9.1.1
torchvision             0.13.0+cu113 @/root/miniconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ----------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/10 13:42:56] detectron2 INFO: Command line arguments: Namespace(config_file='configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=False)
[10/10 13:42:56] detectron2 INFO: Contents of args.config_file=configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv_custom.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://DeepLab/R-103.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "./relations_output_seg_transformer_resnet101/model_best.pth"[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m123.675[39m,[38;5;15m [39m[38;5;15m116.280[39m,[38;5;15m [39m[38;5;15m103.530[39m]
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m58.395[39m,[38;5;15m [39m[38;5;15m57.120[39m,[38;5;15m [39m[38;5;15m57.375[39m]
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_resnet_deeplab_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m,[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m]
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m101
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[[38;5;15m1[39m,[38;5;15m [39m[38;5;15m2[39m,[38;5;15m [39m[38;5;15m4[39m]
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdeeplab[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_TOP_K[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m5.0
[38;5;15m  [39m[38;5;197mPANOPTIC_DEEPLAB[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mSTUFF_AREA[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mNMS_KERNEL[39m[38;5;15m:[39m[38;5;15m [39m41
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mPREDICT_INSTANCES[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m  [39m[38;5;197mPSG_RELATION_NET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENCODER_DEPTH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mTOTAL_RELATIONS[39m[38;5;15m:[39m[38;5;15m [39m56
[38;5;15m    [39m[38;5;197mTOTAL_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m133
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mALPHA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m("psg_train",)
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m("psg_val",)
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m5e-4
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m20000
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGAUSSIAN_SIGMA[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;81m!!python/object/apply:eval[39m[38;5;15m [39m[[38;5;186m"[39m[38;5;186m[int(x[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m0.1[39m[38;5;15m [39m[38;5;186m*[39m[38;5;15m [39m[38;5;186m640)[39m[38;5;15m [39m[38;5;186mfor[39m[38;5;15m [39m[38;5;186mx[39m[38;5;15m [39m[38;5;186min[39m[38;5;15m [39m[38;5;186mrange(5,[39m[38;5;15m [39m[38;5;186m16)][39m[38;5;186m"[39m]
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mchoice[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m960
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m640
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mabsolute[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m[38;5;15m [39m(640, 640)
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./relations_output_seg_transformer_resnet101_alpha5[39m[38;5;186m"[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m

[10/10 13:42:56] detectron2.utils.env INFO: Using a generated random seed 57806643
[10/10 13:43:01] detectron2.engine.defaults INFO: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=0.0001)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=0.0001)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=0.0001)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=0.0001)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=0.0001)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=0.0001)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
  (psg_relation_net): PSGRelationNet(
    (map_dict): ModuleDict(
      (res3): Linear(in_features=512, out_features=256, bias=True)
      (res5): Linear(in_features=2048, out_features=256, bias=True)
    )
    (tf_encoder): Transformer(
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.3, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.3, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.3, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.3, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.3, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.3, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.3, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.3, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.3, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=256, out_features=768, bias=False)
            (attn_drop): Dropout(p=0.3, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.3, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.3, inplace=False)
          )
        )
      )
      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (pos_drop): Dropout(p=0.3, inplace=False)
    )
    (tf_decoder): Attention(
      (qkv): Linear(in_features=256, out_features=512, bias=True)
      (attn_drop): Dropout(p=0.3, inplace=False)
      (proj_cls): Linear(in_features=256, out_features=256, bias=True)
      (proj_rel): Linear(in_features=256, out_features=256, bias=True)
      (proj_drop): Dropout(p=0.3, inplace=False)
    )
    (cls_fc): Linear(in_features=256, out_features=1, bias=True)
    (rel_fc): Linear(in_features=256, out_features=1, bias=True)
  )
)
[10/10 13:43:01] detectron2.projects.panoptic_deeplab.dataset_mapper INFO: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[10/10 13:43:01] detectron2.data.build INFO: Removed 0 images with no usable annotations. 4500 images left.
[10/10 13:43:01] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 25660        |    bicycle    | 913          |      car      | 3591         |
|  motorcycle   | 866          |   airplane    | 89           |      bus      | 433          |
|     train     | 179          |     truck     | 537          |     boat      | 269          |
| traffic light | 883          | fire hydrant  | 59           |   stop sign   | 70           |
| parking meter | 75           |     bench     | 805          |     bird      | 420          |
|      cat      | 65           |      dog      | 267          |     horse     | 478          |
|     sheep     | 415          |      cow      | 448          |   elephant    | 219          |
|     bear      | 29           |     zebra     | 137          |    giraffe    | 140          |
|   backpack    | 1070         |   umbrella    | 1038         |    handbag    | 1651         |
|      tie      | 447          |   suitcase    | 359          |    frisbee    | 218          |
|     skis      | 220          |   snowboard   | 98           |  sports ball  | 805          |
|     kite      | 544          | baseball bat  | 512          | baseball gl.. | 621          |
|  skateboard   | 442          |   surfboard   | 257          | tennis racket | 490          |
|    bottle     | 691          |  wine glass   | 257          |      cup      | 573          |
|     fork      | 105          |     knife     | 188          |     spoon     | 90           |
|     bowl      | 229          |    banana     | 157          |     apple     | 73           |
|   sandwich    | 42           |    orange     | 71           |   broccoli    | 9            |
|    carrot     | 52           |    hot dog    | 55           |     pizza     | 130          |
|     donut     | 104          |     cake      | 134          |     chair     | 2464         |
|     couch     | 169          | potted plant  | 313          |      bed      | 52           |
| dining table  | 444          |    toilet     | 24           |      tv       | 151          |
|    laptop     | 201          |     mouse     | 34           |    remote     | 239          |
|   keyboard    | 26           |  cell phone   | 501          |   microwave   | 14           |
|     oven      | 28           |    toaster    | 0            |     sink      | 23           |
| refrigerator  | 30           |     book      | 431          |     clock     | 168          |
|     vase      | 54           |   scissors    | 17           |  teddy bear   | 88           |
|  hair drier   | 5            |  toothbrush   | 28           |    banner     | 431          |
|    blanket    | 49           |    bridge     | 84           |   cardboard   | 115          |
|    counter    | 56           |    curtain    | 121          |  door-stuff   | 283          |
|  floor-wood   | 148          |    flower     | 118          |     fruit     | 29           |
|    gravel     | 112          |     house     | 349          |     light     | 481          |
| mirror-stuff  | 66           |      net      | 140          |    pillow     | 46           |
|   platform    | 132          | playingfield  | 699          |   railroad    | 128          |
|     river     | 66           |     road      | 1178         |     roof      | 286          |
|     sand      | 295          |      sea      | 228          |     shelf     | 91           |
|     snow      | 146          |    stairs     | 237          |     tent      | 149          |
|     towel     | 53           |  wall-brick   | 281          |  wall-stone   | 90           |
|   wall-tile   | 88           |   wall-wood   | 181          |  water-other  | 67           |
| window-blind  | 66           | window-other  | 565          |  tree-merged  | 2047         |
| fence-merged  | 1051         | ceiling-mer.. | 409          | sky-other-m.. | 1874         |
| cabinet-mer.. | 105          | table-merged  | 321          | floor-other.. | 474          |
| pavement-me.. | 1437         | mountain-me.. | 287          | grass-merged  | 1186         |
|  dirt-merged  | 638          | paper-merged  | 283          | food-other-.. | 118          |
| building-ot.. | 1578         |  rock-merged  | 155          | wall-other-.. | 1685         |
|  rug-merged   | 203          |               |              |               |              |
|     total     | 75788        |               |              |               |              |[0m
[10/10 13:43:01] detectron2.data.build INFO: Using training sampler TrainingSampler
[10/10 13:43:02] detectron2.data.common INFO: Serializing 4500 elements to byte tensors and concatenating them all ...
[10/10 13:43:02] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/10 13:43:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://DeepLab/R-103.pkl ...
[10/10 13:43:02] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[10/10 13:43:02] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4.10.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4.10.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4.10.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4.11.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4.11.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4.11.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4.12.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4.12.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4.12.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4.13.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4.13.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4.13.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4.14.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4.14.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4.14.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4.15.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4.15.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4.15.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4.16.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4.16.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4.16.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4.17.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4.17.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4.17.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4.18.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4.18.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4.18.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4.19.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4.19.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4.19.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4.20.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4.20.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4.20.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4.21.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4.21.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4.21.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4.22.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4.22.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4.22.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4.6.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4.6.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4.6.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4.7.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4.7.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4.7.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4.8.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4.8.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4.8.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4.9.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4.9.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4.9.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
[10/10 13:43:02] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.0.weight[0m
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.center_head.1.weight[0m
[34mins_embed_head.center_predictor.{bias, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res2.project_conv.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res3.project_conv.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.decoder.res5.project_conv.project.weight[0m
[34mins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.depthwise.weight[0m
[34mins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34mins_embed_head.offset_head.pointwise.weight[0m
[34mins_embed_head.offset_predictor.{bias, weight}[0m
[34mpsg_relation_net.cls_fc.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res3.{bias, weight}[0m
[34mpsg_relation_net.map_dict.res5.{bias, weight}[0m
[34mpsg_relation_net.rel_fc.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_cls.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.proj_rel.{bias, weight}[0m
[34mpsg_relation_net.tf_decoder.qkv.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.0.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.1.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.2.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.2.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.attn.proj.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.attn.qkv.weight[0m
[34mpsg_relation_net.tf_encoder.blocks.3.mlp.fc1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.mlp.fc2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.norm1.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.blocks.3.norm2.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.norm.{bias, weight}[0m
[34mpsg_relation_net.tf_encoder.pos_embed[0m
[34mpsg_relation_net.{Q_cls, Q_rel}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res2.project_conv.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.depthwise.weight[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.fuse_conv.pointwise.weight[0m
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res3.project_conv.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight[0m
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.decoder.res5.project_conv.project.weight[0m
[34msem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.depthwise.weight[0m
[34msem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}[0m
[34msem_seg_head.head.pointwise.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[10/10 13:43:02] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mres3.0.conv1.norm.num_batches_tracked[0m
  [35mres3.0.conv2.norm.num_batches_tracked[0m
  [35mres3.0.conv3.norm.num_batches_tracked[0m
  [35mres3.0.shortcut.norm.num_batches_tracked[0m
  [35mres3.1.conv1.norm.num_batches_tracked[0m
  [35mres3.1.conv2.norm.num_batches_tracked[0m
  [35mres3.1.conv3.norm.num_batches_tracked[0m
  [35mres3.2.conv1.norm.num_batches_tracked[0m
  [35mres3.2.conv2.norm.num_batches_tracked[0m
  [35mres3.2.conv3.norm.num_batches_tracked[0m
  [35mres3.3.conv1.norm.num_batches_tracked[0m
  [35mres3.3.conv2.norm.num_batches_tracked[0m
  [35mres3.3.conv3.norm.num_batches_tracked[0m
  [35mres4.0.conv1.norm.num_batches_tracked[0m
  [35mres4.0.conv2.norm.num_batches_tracked[0m
  [35mres4.0.conv3.norm.num_batches_tracked[0m
  [35mres4.0.shortcut.norm.num_batches_tracked[0m
  [35mres4.1.conv1.norm.num_batches_tracked[0m
  [35mres4.1.conv2.norm.num_batches_tracked[0m
  [35mres4.1.conv3.norm.num_batches_tracked[0m
  [35mres4.10.conv1.norm.num_batches_tracked[0m
  [35mres4.10.conv2.norm.num_batches_tracked[0m
  [35mres4.10.conv3.norm.num_batches_tracked[0m
  [35mres4.11.conv1.norm.num_batches_tracked[0m
  [35mres4.11.conv2.norm.num_batches_tracked[0m
  [35mres4.11.conv3.norm.num_batches_tracked[0m
  [35mres4.12.conv1.norm.num_batches_tracked[0m
  [35mres4.12.conv2.norm.num_batches_tracked[0m
  [35mres4.12.conv3.norm.num_batches_tracked[0m
  [35mres4.13.conv1.norm.num_batches_tracked[0m
  [35mres4.13.conv2.norm.num_batches_tracked[0m
  [35mres4.13.conv3.norm.num_batches_tracked[0m
  [35mres4.14.conv1.norm.num_batches_tracked[0m
  [35mres4.14.conv2.norm.num_batches_tracked[0m
  [35mres4.14.conv3.norm.num_batches_tracked[0m
  [35mres4.15.conv1.norm.num_batches_tracked[0m
  [35mres4.15.conv2.norm.num_batches_tracked[0m
  [35mres4.15.conv3.norm.num_batches_tracked[0m
  [35mres4.16.conv1.norm.num_batches_tracked[0m
  [35mres4.16.conv2.norm.num_batches_tracked[0m
  [35mres4.16.conv3.norm.num_batches_tracked[0m
  [35mres4.17.conv1.norm.num_batches_tracked[0m
  [35mres4.17.conv2.norm.num_batches_tracked[0m
  [35mres4.17.conv3.norm.num_batches_tracked[0m
  [35mres4.18.conv1.norm.num_batches_tracked[0m
  [35mres4.18.conv2.norm.num_batches_tracked[0m
  [35mres4.18.conv3.norm.num_batches_tracked[0m
  [35mres4.19.conv1.norm.num_batches_tracked[0m
  [35mres4.19.conv2.norm.num_batches_tracked[0m
  [35mres4.19.conv3.norm.num_batches_tracked[0m
  [35mres4.2.conv1.norm.num_batches_tracked[0m
  [35mres4.2.conv2.norm.num_batches_tracked[0m
  [35mres4.2.conv3.norm.num_batches_tracked[0m
  [35mres4.20.conv1.norm.num_batches_tracked[0m
  [35mres4.20.conv2.norm.num_batches_tracked[0m
  [35mres4.20.conv3.norm.num_batches_tracked[0m
  [35mres4.21.conv1.norm.num_batches_tracked[0m
  [35mres4.21.conv2.norm.num_batches_tracked[0m
  [35mres4.21.conv3.norm.num_batches_tracked[0m
  [35mres4.22.conv1.norm.num_batches_tracked[0m
  [35mres4.22.conv2.norm.num_batches_tracked[0m
  [35mres4.22.conv3.norm.num_batches_tracked[0m
  [35mres4.3.conv1.norm.num_batches_tracked[0m
  [35mres4.3.conv2.norm.num_batches_tracked[0m
  [35mres4.3.conv3.norm.num_batches_tracked[0m
  [35mres4.4.conv1.norm.num_batches_tracked[0m
  [35mres4.4.conv2.norm.num_batches_tracked[0m
  [35mres4.4.conv3.norm.num_batches_tracked[0m
  [35mres4.5.conv1.norm.num_batches_tracked[0m
  [35mres4.5.conv2.norm.num_batches_tracked[0m
  [35mres4.5.conv3.norm.num_batches_tracked[0m
  [35mres4.6.conv1.norm.num_batches_tracked[0m
  [35mres4.6.conv2.norm.num_batches_tracked[0m
  [35mres4.6.conv3.norm.num_batches_tracked[0m
  [35mres4.7.conv1.norm.num_batches_tracked[0m
  [35mres4.7.conv2.norm.num_batches_tracked[0m
  [35mres4.7.conv3.norm.num_batches_tracked[0m
  [35mres4.8.conv1.norm.num_batches_tracked[0m
  [35mres4.8.conv2.norm.num_batches_tracked[0m
  [35mres4.8.conv3.norm.num_batches_tracked[0m
  [35mres4.9.conv1.norm.num_batches_tracked[0m
  [35mres4.9.conv2.norm.num_batches_tracked[0m
  [35mres4.9.conv3.norm.num_batches_tracked[0m
  [35mres5.0.conv1.norm.num_batches_tracked[0m
  [35mres5.0.conv2.norm.num_batches_tracked[0m
  [35mres5.0.conv3.norm.num_batches_tracked[0m
  [35mres5.0.shortcut.norm.num_batches_tracked[0m
  [35mres5.1.conv1.norm.num_batches_tracked[0m
  [35mres5.1.conv2.norm.num_batches_tracked[0m
  [35mres5.1.conv3.norm.num_batches_tracked[0m
  [35mres5.2.conv1.norm.num_batches_tracked[0m
  [35mres5.2.conv2.norm.num_batches_tracked[0m
  [35mres5.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
  [35mstem.conv2.norm.num_batches_tracked[0m
  [35mstem.conv3.norm.num_batches_tracked[0m
  [35mstem.fc.{bias, weight}[0m
[10/10 13:43:02] detectron2.engine.train_loop INFO: Starting training from iteration 0
[10/10 14:06:46] detectron2.data.build INFO: Distribution of instances among all 133 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 1980         |    bicycle    | 80           |      car      | 332          |
|  motorcycle   | 51           |   airplane    | 15           |      bus      | 38           |
|     train     | 21           |     truck     | 70           |     boat      | 53           |
| traffic light | 93           | fire hydrant  | 9            |   stop sign   | 8            |
| parking meter | 1            |     bench     | 56           |     bird      | 86           |
|      cat      | 8            |      dog      | 18           |     horse     | 42           |
|     sheep     | 47           |      cow      | 30           |   elephant    | 29           |
|     bear      | 10           |     zebra     | 47           |    giraffe    | 33           |
|   backpack    | 55           |   umbrella    | 44           |    handbag    | 130          |
|      tie      | 33           |   suitcase    | 18           |    frisbee    | 7            |
|     skis      | 44           |   snowboard   | 11           |  sports ball  | 46           |
|     kite      | 94           | baseball bat  | 24           | baseball gl.. | 32           |
|  skateboard   | 37           |   surfboard   | 55           | tennis racket | 30           |
|    bottle     | 77           |  wine glass   | 41           |      cup      | 104          |
|     fork      | 23           |     knife     | 30           |     spoon     | 23           |
|     bowl      | 51           |    banana     | 52           |     apple     | 14           |
|   sandwich    | 5            |    orange     | 13           |   broccoli    | 3            |
|    carrot     | 16           |    hot dog    | 8            |     pizza     | 14           |
|     donut     | 9            |     cake      | 15           |     chair     | 197          |
|     couch     | 17           | potted plant  | 10           |      bed      | 10           |
| dining table  | 45           |    toilet     | 6            |      tv       | 12           |
|    laptop     | 16           |     mouse     | 2            |    remote     | 23           |
|   keyboard    | 2            |  cell phone   | 25           |   microwave   | 0            |
|     oven      | 3            |    toaster    | 0            |     sink      | 7            |
| refrigerator  | 2            |     book      | 74           |     clock     | 11           |
|     vase      | 1            |   scissors    | 0            |  teddy bear   | 33           |
|  hair drier   | 0            |  toothbrush   | 8            |    banner     | 29           |
|    blanket    | 13           |    bridge     | 9            |   cardboard   | 14           |
|    counter    | 7            |    curtain    | 12           |  door-stuff   | 30           |
|  floor-wood   | 16           |    flower     | 9            |     fruit     | 6            |
|    gravel     | 10           |     house     | 33           |     light     | 41           |
| mirror-stuff  | 7            |      net      | 7            |    pillow     | 7            |
|   platform    | 16           | playingfield  | 39           |   railroad    | 17           |
|     river     | 10           |     road      | 101          |     roof      | 20           |
|     sand      | 28           |      sea      | 53           |     shelf     | 19           |
|     snow      | 27           |    stairs     | 16           |     tent      | 11           |
|     towel     | 12           |  wall-brick   | 24           |  wall-stone   | 15           |
|   wall-tile   | 12           |   wall-wood   | 34           |  water-other  | 10           |
| window-blind  | 8            | window-other  | 40           |  tree-merged  | 224          |
| fence-merged  | 91           | ceiling-mer.. | 32           | sky-other-m.. | 233          |
| cabinet-mer.. | 16           | table-merged  | 46           | floor-other.. | 42           |
| pavement-me.. | 134          | mountain-me.. | 31           | grass-merged  | 128          |
|  dirt-merged  | 57           | paper-merged  | 29           | food-other-.. | 24           |
| building-ot.. | 152          |  rock-merged  | 22           | wall-other-.. | 145          |
|  rug-merged   | 14           |               |              |               |              |
|     total     | 7001         |               |              |               |              |[0m
[10/10 14:06:46] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[10/10 14:06:46] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[10/10 14:06:46] detectron2.data.common INFO: Serialized dataset takes 0.86 MiB
[10/10 14:06:46] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[10/10 14:07:00] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0018 s/iter. Inference: 0.0850 s/iter. Eval: 0.0280 s/iter. Total: 0.1148 s/iter. ETA=0:00:27
[10/10 14:07:05] detectron2.evaluation.evaluator INFO: Inference done 53/250. Dataloading: 0.0013 s/iter. Inference: 0.0894 s/iter. Eval: 0.0280 s/iter. Total: 0.1187 s/iter. ETA=0:00:23
[10/10 14:07:10] detectron2.evaluation.evaluator INFO: Inference done 95/250. Dataloading: 0.0014 s/iter. Inference: 0.0897 s/iter. Eval: 0.0288 s/iter. Total: 0.1200 s/iter. ETA=0:00:18
[10/10 14:07:15] detectron2.evaluation.evaluator INFO: Inference done 138/250. Dataloading: 0.0014 s/iter. Inference: 0.0892 s/iter. Eval: 0.0284 s/iter. Total: 0.1190 s/iter. ETA=0:00:13
[10/10 14:07:20] detectron2.evaluation.evaluator INFO: Inference done 182/250. Dataloading: 0.0015 s/iter. Inference: 0.0887 s/iter. Eval: 0.0280 s/iter. Total: 0.1182 s/iter. ETA=0:00:08
[10/10 14:07:25] detectron2.evaluation.evaluator INFO: Inference done 226/250. Dataloading: 0.0015 s/iter. Inference: 0.0881 s/iter. Eval: 0.0279 s/iter. Total: 0.1175 s/iter. ETA=0:00:02
[10/10 14:07:28] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:29.011396 (0.118414 s / iter per device, on 2 devices)
[10/10 14:07:28] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:21 (0.087612 s / iter per device, on 2 devices)
[10/10 14:07:41] detectron2.engine.hooks WARNING: Given val metric relation_mean_recall/mean_recall does not seem to be computed/stored.Will not be checkpointing based on it.
